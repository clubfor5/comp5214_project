{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/zhangzheng/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/zhangzheng/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/zhangzheng/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/zhangzheng/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/zhangzheng/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/zhangzheng/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/zhangzheng/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/zhangzheng/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/zhangzheng/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/zhangzheng/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/zhangzheng/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/zhangzheng/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam,sgd\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import scale\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "import tensorflow.keras.layers as L\n",
    "import tensorflow.keras.models as M\n",
    "import tensorflow.keras.backend as K\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import scipy.stats as stats\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import math\n",
    "import glob\n",
    "import pickle\n",
    "import random\n",
    "import os\n",
    "\n",
    "\n",
    "#train_files,test_files = get_data_files()\n",
    "#print(train_files)\n",
    "def train_val_split(train_AP_features,train_labels,fp_ratio):\n",
    "    #generate len(train_AP_features) of floats in between 0 and 1\n",
    "    train_val_split = np.random.rand(len(train_AP_features))\n",
    "    #convert train_val_split to an array of booleans: if elem < 0.7 = true, else: false\n",
    "    train_val_split = train_val_split < fp_ratio #should contain ~70% percent true\n",
    "    # We will then split our given training set into training + validation \n",
    "    train_X = train_AP_features[train_val_split]\n",
    "    train_y = train_labels[train_val_split]\n",
    "    val_X = train_AP_features[~train_val_split]\n",
    "    val_y = train_labels[~train_val_split]\n",
    "    return train_X,train_y, val_X, val_y\n",
    "\n",
    "def normalization(data):\n",
    "    minVals = data.min(0)\n",
    "    maxVals = data.max(0)\n",
    "    ranges = maxVals - minVals\n",
    "    normData = (data - minVals)/ranges\n",
    "    return normData,ranges,minVals\n",
    "\n",
    "def load_data(file_name):\n",
    "    df = pd.read_csv(file_name,header = 0)\n",
    "    #print(df.head(2))\n",
    "    AP_strengths = df.loc[:,'WAP001':'WAP520']\n",
    "    AP_strengths = AP_strengths.replace([100], [-100])\n",
    "    print(AP_strengths.head(2))\n",
    "    df_xy = df.loc[:,'LONGITUDE':'LATITUDE']\n",
    "    labels = np.asarray(df_xy)\n",
    "    AP_features = (np.asarray(AP_strengths))\n",
    "    \n",
    "    building_ids_str = df[\"BUILDINGID\"].map(str) #convert all the building ids to strings\n",
    "    building_floors_str = df[\"FLOOR\"].map(str) #convert all the building floors to strings\n",
    "    return AP_features, building_ids_str, building_floors_str, labels\n",
    "\n",
    "\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "    return math.sqrt((y_true[0]-y_pred[0])**2+(y_true[1]-y_pred[1])**2)\n",
    "\n",
    "\n",
    "def rms(list):\n",
    "    sum = 0\n",
    "    for term in list:\n",
    "        sum+= term*term\n",
    "    rms = math.sqrt(sum / len(list))\n",
    "    return rms\n",
    "def save_to_log(file_name,preds_pos):\n",
    "    write_file = open(file_name,'w')\n",
    "    for pos in preds_pos:\n",
    "        line = str(pos[0])+','+str(pos[1])+'\\n'\n",
    "        write_file.write(line)\n",
    "    return \n",
    "def load_log(file_name):\n",
    "    read_file = open(file_name,'r')\n",
    "    lines = read_file.readlines()\n",
    "    pred_pos = []\n",
    "    for line in lines:\n",
    "        pos = line.split(',')\n",
    "        x = float(pos[0])\n",
    "        y = float(pos[1])\n",
    "        pred_pos.append([x,y])\n",
    "    return pred_pos\n",
    "\n",
    "def cdf(error):\n",
    "    count = len(error)\n",
    "    cdf_y = [i/count for i in range(count)]\n",
    "    error_sorted = sorted(error)\n",
    "    plt.xlim(0,100)\n",
    "    plt.ylim(0,1)\n",
    "    plt.plot(error_sorted, cdf_y)\n",
    "    plt.show()\n",
    "    return cdf_y,error_sorted\n",
    "\n",
    "def error_analysis(pred_y,true_y):\n",
    "    error =np.sqrt((pred_y[:,0]-true_y[:,0])**2+(pred_y[:,1]-true_y[:,1])**2)\n",
    "    rms_error = rms(error)\n",
    "    print('rms_error:', rms_error)\n",
    "    mean_error = sum(error)/len(error)\n",
    "    print('mean_error:', mean_error)\n",
    "    print(\"generating cdf:\")\n",
    "    cdf_y,error_sorted = cdf(error)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   WAP001  WAP002  WAP003  WAP004  WAP005  WAP006  WAP007  WAP008  WAP009  \\\n",
      "0    -100    -100    -100    -100    -100    -100    -100    -100    -100   \n",
      "1    -100    -100    -100    -100    -100    -100    -100    -100    -100   \n",
      "\n",
      "   WAP010  ...  WAP511  WAP512  WAP513  WAP514  WAP515  WAP516  WAP517  \\\n",
      "0    -100  ...    -100    -100    -100    -100    -100    -100    -100   \n",
      "1    -100  ...    -100    -100    -100    -100    -100    -100    -100   \n",
      "\n",
      "   WAP518  WAP519  WAP520  \n",
      "0    -100    -100    -100  \n",
      "1    -100    -100    -100  \n",
      "\n",
      "[2 rows x 520 columns]\n"
     ]
    }
   ],
   "source": [
    "AP_features, building_ids_str, building_floors_str, labels = load_data('trainingData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### input: \n",
    "def mlp(input_data):\n",
    "    wapid_dim = input_data[0].shape[1]\n",
    "    wapid_input_layer = L.Input(shape=(wapid_dim,))\n",
    "    wap_emb = L.Embedding(520,40)(wapid_input_layer)\n",
    "    wap_emb = L.BatchNormalization()(wap_emb)\n",
    "    wap_emb = L.Flatten()(wap_emb)\n",
    "    \n",
    "    rssi_f_dim = input_data[1].shape[1]\n",
    "    rssi_f_input_layer = L.Input(shape=(rssi_f_dim,))\n",
    "    rssi_f = L.BatchNormalization()(rssi_f_input_layer)\n",
    "    rssi_f_feature = L.Dense(16*40, activation='relu')(rssi_f)\n",
    "    \n",
    "    \n",
    "    input_site_layer = L.Input(shape=(1,))\n",
    "    site_emb = L.Embedding(13, 1)(input_site_layer)\n",
    "    site_emb = L.Flatten()(site_emb)\n",
    "    site_emb = L.BatchNormalization()(site_emb)\n",
    "    x = L.Concatenate(axis=1)([wap_emb, rssi_f_feature])\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.Dropout(0.1)(x)\n",
    "    x = L.Dense(256, activation='relu')(x)\n",
    "    x = L.Dropout(0.2)(x)\n",
    "    #x = L.Reshape((-1, 1))(x)\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.Dense(128,activation='relu')(x)\n",
    "    x = L.Dropout(0.1)(x)\n",
    "    x = L.Dense(64, activation='relu')(x)\n",
    "    x = L.Concatenate(axis=1)([x,site_emb])\n",
    "    x = L.Dense(16, activation='relu')(x)\n",
    "    #x = L.Dropout(0.1)(x)\n",
    "    output_layer_1 = L.Dense(2, name='xy')(x)\n",
    "    model = M.Model([wapid_input_layer, rssi_f_input_layer, input_site_layer], [output_layer_1])\n",
    "    model.compile(optimizer=tf.optimizers.Adam(lr=0.001), loss='mse', metrics=['mse'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "def cnn(input_data):\n",
    "    print(\"using CNN\")\n",
    "    wapid_dim = input_data[0].shape[1]\n",
    "    wapid_input_layer = L.Input(shape=(wapid_dim,))\n",
    "    wap_emb = L.Embedding(520,40)(wapid_input_layer)\n",
    "    wap_emb = L.BatchNormalization()(wap_emb)\n",
    "    wap_emb = L.Flatten()(wap_emb)\n",
    "    \n",
    "    rssi_f_dim = input_data[1].shape[1]\n",
    "    rssi_f_input_layer = L.Input(shape=(rssi_f_dim,))\n",
    "    rssi_f = L.BatchNormalization()(rssi_f_input_layer)\n",
    "    rssi_f_feature = L.Dense(16*40, activation='relu')(rssi_f)\n",
    "    \n",
    "    \n",
    "    input_site_layer = L.Input(shape=(1,))\n",
    "    print(\"input_site_layer\", input_site_layer.shape)\n",
    "    site_emb = L.Embedding(13, 1)(input_site_layer)\n",
    "    print(\"site_emb1\", site_emb.shape)\n",
    "    site_emb = L.Flatten()(site_emb)\n",
    "    print(\"site_emb2\", site_emb.shape)\n",
    "    site_emb = L.BatchNormalization()(site_emb)\n",
    "    print(\"site_emb3\", site_emb.shape)\n",
    "    x = L.Concatenate(axis=1)([wap_emb, rssi_f_feature])\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.Dropout(0.2)(x)\n",
    "    x = L.Dense(256, activation='relu')(x)\n",
    "    x = L.Dropout(0.1)(x)\n",
    "    x = L.Dense(128, activation='relu')(x)\n",
    "    print(\"before\",x.shape)\n",
    "    x = L.Reshape((128, 1))(x)\n",
    "    print(\"before2\",x.shape)\n",
    "    x = L.BatchNormalization()(x)   # input 128\n",
    "    x = L.Conv1D(32, 3, strides=1, dilation_rate=1, activation='relu')(x)   # input 128, output 126\n",
    "    print(\"CNN1\",x.shape)\n",
    "    y = x\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.Conv1D(64, 5, strides=2, dilation_rate=1, activation='relu')(x)   # input 126, output (126-5+0)/2+1 = 61\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.Conv1D(128, 7, strides=2, dilation_rate=1, activation='relu')(x)  # input 61, output (61-7+0)/2+1 = 28\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.Conv1D(64, 9, strides=1, dilation_rate=1, activation='relu')(x)  # input 23, output (28-9+0)/1+1 = 20\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.Conv1D(32, 5, strides=1, dilation_rate=1, activation='relu')(x)   # input 20, output (20-5+0)/1+1 = 16\n",
    "    print(\"CNN_5 \", x.shape)\n",
    "    x = L.Concatenate(axis=1)([x, y])\n",
    "    x = L.BatchNormalization()(x)\n",
    "    print(\"CNN_res \", x.shape)\n",
    "    x = L.Conv1D(1, 1, strides=1, dilation_rate=1, activation='relu')(x)    # gloabl average pooling\n",
    "    x = L.BatchNormalization()(x)  \n",
    "    print(\"after cnn\", x.shape)\n",
    "    x = L.Flatten()(x)\n",
    "    print(\"after flatten\", x.shape)\n",
    "    x = L.Dense(64, activation='relu')(x)\n",
    "    x = L.Concatenate(axis=1)([x,site_emb])\n",
    "    x = L.Dense(32, activation='relu')(x)\n",
    "    output_layer_1 = L.Dense(2, name='xy')(x)\n",
    "    model = M.Model([wapid_input_layer, rssi_f_input_layer, input_site_layer], [output_layer_1])\n",
    "    model.compile(optimizer=tf.optimizers.Adam(lr=0.001), loss='mse', metrics=['mse'])\n",
    "    return model\n",
    "\n",
    "def cnn_lstm(input_data):\n",
    "    wapid_dim = input_data[0].shape[1]\n",
    "    wapid_input_layer = L.Input(shape=(wapid_dim,))\n",
    "    wap_emb = L.Embedding(520,40)(wapid_input_layer)\n",
    "    wap_emb = L.BatchNormalization()(wap_emb)\n",
    "    wap_emb = L.Flatten()(wap_emb)\n",
    "    \n",
    "    rssi_f_dim = input_data[1].shape[1]\n",
    "    rssi_f_input_layer = L.Input(shape=(rssi_f_dim,))\n",
    "    rssi_f = L.BatchNormalization()(rssi_f_input_layer)\n",
    "    rssi_f_feature = L.Dense(16*40, activation='relu')(rssi_f)\n",
    "    \n",
    "    \n",
    "    input_site_layer = L.Input(shape=(1,))\n",
    "    site_emb = L.Embedding(13, 1)(input_site_layer)\n",
    "    site_emb = L.Flatten()(site_emb)\n",
    "    site_emb = L.BatchNormalization()(site_emb)\n",
    "    x = L.Concatenate(axis=1)([wap_emb, rssi_f_feature])\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.Dropout(0.2)(x)\n",
    "    x = L.Dense(256, activation='relu')(x)\n",
    "    x = L.Dropout(0.1)(x)\n",
    "    x = L.Dense(128, activation='relu')(x)\n",
    "    #x = L.Dropout(0.2)(x)\n",
    "    x = L.Reshape((128, 1))(x)\n",
    "    # x = L.Reshape((-1, 1))(x)\n",
    "    x = L.BatchNormalization()(x)\n",
    "    \n",
    "    x = L.Conv1D(32, 3, strides=1, dilation_rate=1, activation='relu')(x)   # input 128, output 126\n",
    "    y = x\n",
    "    print(\"CNN1\",x.shape)\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.Conv1D(64, 5, strides=2, dilation_rate=1, activation='relu')(x)   # input 126, output (126-5+0)/2+1 = 61\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.Conv1D(128, 7, strides=2, dilation_rate=1, activation='relu')(x)  # input 61, output (61-7+0)/2+1 = 28\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.Conv1D(64, 9, strides=1, dilation_rate=1, activation='relu')(x)  # input 23, output (28-9+0)/1+1 = 20\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.Conv1D(32, 5, strides=1, dilation_rate=1, activation='relu')(x)   # input 20, output (20-5+0)/1+1 = 16\n",
    "    x = L.BatchNormalization()(x)\n",
    "    # x = L.Concatenate(axis=1)([x, y])\n",
    "    # x = L.Dense(64, activation='relu')(x)\n",
    "    x = L.Conv1D(1, 1, strides=1, dilation_rate=1, activation='relu')(x)    # gloabl average pooling\n",
    "    print(\"after conv1D\", x.shape)\n",
    "    x = L.BatchNormalization()(x) \n",
    "    x = L.LSTM(128, dropout=0, return_sequences=True, activation='sigmoid')(x)\n",
    "    x = L.LSTM(16, dropout=0, return_sequences=False, activation='sigmoid')(x)\n",
    "    print(\"after LSTM \", x.shape)\n",
    "    x = L.Concatenate(axis=1)([x,site_emb]) \n",
    "    x = L.Dense(64, activation='relu')(x)\n",
    "    x = L.Dense(16, activation='relu')(x)\n",
    "    #x = L.Dropout(0.1)(x)\n",
    "    output_layer_1 = L.Dense(2, name='xy', activation='sigmoid')(x)\n",
    "    model = M.Model([wapid_input_layer, rssi_f_input_layer, input_site_layer], [output_layer_1])\n",
    "    model.compile(optimizer=tf.optimizers.Adam(lr=0.001), loss='mse', metrics=['mse'])\n",
    "    return model\n",
    "\n",
    "def lstm(input_data):\n",
    "    wapid_dim = input_data[0].shape[1]\n",
    "    wapid_input_layer = L.Input(shape=(wapid_dim,))\n",
    "    wap_emb = L.Embedding(520,40)(wapid_input_layer)\n",
    "    wap_emb = L.BatchNormalization()(wap_emb)\n",
    "    wap_emb = L.Flatten()(wap_emb)\n",
    "    \n",
    "    rssi_f_dim = input_data[1].shape[1]\n",
    "    rssi_f_input_layer = L.Input(shape=(rssi_f_dim,))\n",
    "    rssi_f = L.BatchNormalization()(rssi_f_input_layer)\n",
    "    rssi_f_feature = L.Dense(16*40, activation='relu')(rssi_f)\n",
    "    \n",
    "    \n",
    "    input_site_layer = L.Input(shape=(1,))\n",
    "    site_emb = L.Embedding(13, 1)(input_site_layer)\n",
    "    site_emb = L.Flatten()(site_emb)\n",
    "    site_emb = L.BatchNormalization()(site_emb)\n",
    "    x = L.Concatenate(axis=1)([wap_emb, rssi_f_feature])\n",
    "    x = L.BatchNormalization()(x)\n",
    "    #x = L.Dropout(0.2)(x)\n",
    "    #x = L.Dense(256, activation='relu')(x)\n",
    "    x = L.Dropout(0.1)(x)\n",
    "    x = L.Dense(128, activation='relu')(x)\n",
    "    #x = L.Dropout(0.2)(x)\n",
    "    x = L.Reshape((-1, 1))(x)\n",
    "    print(x.shape)\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.LSTM(128, dropout=0.1, recurrent_dropout=0, return_sequences=True, activation='sigmoid')(x)\n",
    "    x = L.LSTM(64, dropout=0.1, return_sequences=False, activation='sigmoid')(x)\n",
    "    #x = L.Dense(128,activation='relu')(x)\n",
    "    #x = L.Dropout(0.2)(x)\n",
    "    #x = L.Reshape((-1, 1))(x)\n",
    "    x = L.Dense(64, activation='relu')(x)\n",
    "    #x = L.LSTM(16, dropout=0, return_sequences=False, activation='relu')(x)\n",
    "    x = L.Concatenate(axis=1)([x,site_emb])\n",
    "    x = L.Dense(16, activation='relu')(x)\n",
    "    #x = L.Dropout(0.1)(x)\n",
    "    output_layer_1 = L.Dense(2, name='xy')(x)\n",
    "    model = M.Model([wapid_input_layer, rssi_f_input_layer, input_site_layer], [output_layer_1])\n",
    "    model.compile(optimizer=tf.optimizers.Adam(lr=0.001), loss='mse', metrics=['mse'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   WAP001  WAP002  WAP003  WAP004  WAP005  WAP006  WAP007  WAP008  WAP009  \\\n",
      "0     100     100     100     100     100     100     100     100     100   \n",
      "1     100     100     100     100     100     100     100     100     100   \n",
      "\n",
      "   WAP010  ...  WAP520  LONGITUDE      LATITUDE  FLOOR  BUILDINGID  SPACEID  \\\n",
      "0     100  ...     100 -7541.2643  4.864921e+06      2           1      106   \n",
      "1     100  ...     100 -7536.6212  4.864934e+06      2           1      106   \n",
      "\n",
      "   RELATIVEPOSITION  USERID  PHONEID   TIMESTAMP  \n",
      "0                 2       2       23  1371713733  \n",
      "1                 2       2       23  1371713691  \n",
      "\n",
      "[2 rows x 529 columns]\n",
      "floor id (19937, 1)\n",
      "building id: (19937,)\n",
      "[-97 -94 -94 -94 -90 -90 -88 -88 -87 -86 -86 -84 -83 -83 -83 -80]\n",
      "[154  35 141 155  90  89 102 190 103 150 191 172 171   7 149 247]\n",
      "[[-150 -150 -150 ... -150 -150 -150]\n",
      " [-150 -150 -150 ... -150 -150 -150]\n",
      " [-150 -150 -150 ... -150 -150 -150]\n",
      " ...\n",
      " [-150 -150 -150 ... -150 -150 -150]\n",
      " [-150 -150 -150 ... -150 -150 -150]\n",
      " [-150 -150 -150 ... -150 -150 -150]]\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 16)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 16, 40)       20800       input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 16)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 16, 40)       160         embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 16)           64          input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 640)          0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 640)          10880       batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1280)         0           flatten_2[0][0]                  \n",
      "                                                                 dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 1280)         5120        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1280)         0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 256)          327936      dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 256)          0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 256)          1024        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 128)          32896       batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 1, 1)         13          input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 128)          0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 1)            0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 64)           8256        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 1)            4           flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 65)           0           dense_8[0][0]                    \n",
      "                                                                 batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 16)           1056        concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "xy (Dense)                      (None, 2)            34          dense_9[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 408,243\n",
      "Trainable params: 405,057\n",
      "Non-trainable params: 3,186\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 16)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 16, 40)       20800       input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 16)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 16, 40)       160         embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 16)           64          input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 640)          0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 640)          10880       batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1280)         0           flatten_2[0][0]                  \n",
      "                                                                 dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 1280)         5120        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1280)         0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 256)          327936      dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 256)          0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 256)          1024        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 128)          32896       batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 1, 1)         13          input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 128)          0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 1)            0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 64)           8256        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 1)            4           flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 65)           0           dense_8[0][0]                    \n",
      "                                                                 batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 16)           1056        concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "xy (Dense)                      (None, 2)            34          dense_9[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 408,243\n",
      "Trainable params: 405,057\n",
      "Non-trainable params: 3,186\n",
      "__________________________________________________________________________________________________\n",
      "[  -7691.3384     4864745.74501597] [390.51940991 270.94278403]\n",
      "   WAP001  WAP002  WAP003  WAP004  WAP005  WAP006  WAP007  WAP008  WAP009  \\\n",
      "0     100     100     100     100     100     100     100     100     100   \n",
      "1     100     100     100     100     100     100     100     100     100   \n",
      "\n",
      "   WAP010  ...  WAP520    LONGITUDE      LATITUDE  FLOOR  BUILDINGID  SPACEID  \\\n",
      "0     100  ...     100 -7515.916799  4.864890e+06      1           1        0   \n",
      "1     100  ...     100 -7383.867221  4.864840e+06      4           2        0   \n",
      "\n",
      "   RELATIVEPOSITION  USERID  PHONEID   TIMESTAMP  \n",
      "0                 0       0        0  1380872703  \n",
      "1                 0       0       13  1381155054  \n",
      "\n",
      "[2 rows x 529 columns]\n",
      "test floor id (1111, 1)\n",
      "test building id: (1111, 1)\n",
      "[-150 -150 -150 -150 -150 -150 -150 -150 -150 -150 -150 -150 -150 -150\n",
      " -150  -91    1] (1111, 17)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'one hot encode the dummy_labels.\\nthis is done because dummy_labels is a dataframe with the labels (BUILDINGID+FLOOR) \\nas the column names\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#import tensorflow_addons as tfa\n",
    "#from tensorflow_addons.layers import WeightNormalization\n",
    "#from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "path_train = \"trainingData.csv\"\n",
    "path_validation = \"validationData.csv\"\n",
    "train_df = pd.read_csv(path_train,header = 0)\n",
    "print(train_df.head(2))\n",
    "\n",
    "train_AP_strengths =train_df.loc[:,'WAP001':'WAP520']\n",
    "#train_AP_features= np.array(train_AP_strengths.replace([100], [-100]))\n",
    "building_ids_str = train_df[\"BUILDINGID\"].map(str) #convert all the building ids to strings\n",
    "building_floors_str = train_df[\"FLOOR\"].map(str) #convert all the building floors to strings\n",
    "#print(id_label)\n",
    "floor_enc = LabelEncoder()\n",
    "floor_enc.fit(building_floors_str)\n",
    "floor_id = floor_enc.transform(building_floors_str)\n",
    "floor_id = floor_id.reshape(-1,1)\n",
    "print(\"floor id\",(floor_id.shape))\n",
    "building_enc = LabelEncoder()\n",
    "building_enc.fit(building_ids_str)\n",
    "building_id = building_enc.transform(building_ids_str)\n",
    "train_building_id = building_id.reshape(-1,1)\n",
    "print(\"building id:\",(building_id.shape))\n",
    "\n",
    "train_AP_features = np.array(train_AP_strengths.replace([100],[-150]))\n",
    "##### 1) RSSI_FLOOR 2) SSID 3) BUILDING_ID\n",
    "train_id = np.argsort(train_AP_features)[:,504:520]\n",
    "train_rssi = np.sort(train_AP_features)[:,504:520]\n",
    "print(train_rssi[10])\n",
    "print(train_id[10])\n",
    "print(train_AP_features[train_id[10]])\n",
    "#train_rssi_floor = np.hstack((train_rssi,floor_id))\n",
    "#print(train_rssi_floor[0], train_rssi_floor.shape)\n",
    "#print(train_id[0],train_rssi[0],train_AP_features[0])\n",
    "\n",
    "input_data = [train_id, train_rssi, train_building_id]\n",
    "\n",
    "# model = lstm(input_data)\n",
    "model = mlp(input_data)\n",
    "# model = cnn_lstm(input_data)\n",
    "model.summary()\n",
    "\n",
    "train_df_LL = train_df.loc[:,'LONGITUDE':'LATITUDE']\n",
    "train_labels = np.asarray(train_df_LL)\n",
    "train_y,ranges,bias =  normalization(train_labels)\n",
    "print(bias,ranges)\n",
    "test_df = pd.read_csv(path_validation,header = 0)\n",
    "print(test_df.head(2))\n",
    "test_AP_strengths =test_df.loc[:,'WAP001':'WAP520']\n",
    "#test_AP_features = np.array(test_AP_strengths.replace([100], [-100]))\n",
    "test_building_ids_str = test_df[\"BUILDINGID\"].map(str) #convert all the building ids to strings\n",
    "test_building_floors_str = test_df[\"FLOOR\"].map(str) #convert all the building floors to strings\n",
    "#print(id_label)\n",
    "test_floor_enc = LabelEncoder()\n",
    "test_floor_enc.fit(building_floors_str)\n",
    "test_floor_id = test_floor_enc.transform(test_building_floors_str)\n",
    "test_floor_id = test_floor_id.reshape(-1,1)\n",
    "print(\"test floor id\",(test_floor_id.shape))\n",
    "test_building_enc = LabelEncoder()\n",
    "test_building_enc.fit(test_building_ids_str)\n",
    "test_building_id = test_building_enc.transform(test_building_ids_str)\n",
    "test_building_id = test_building_id.reshape(-1,1)\n",
    "print(\"test building id:\",(test_building_id.shape))\n",
    "test_AP_features = np.array(test_AP_strengths.replace([100],[-150]))\n",
    "test_id = np.argsort(test_AP_features)[:,504:520]\n",
    "test_rssi = np.sort(test_AP_features)[:,504:520]\n",
    "\n",
    "test_rssi_floor = np.hstack((test_rssi,test_floor_id))\n",
    "print(test_rssi_floor[0], test_rssi_floor.shape)\n",
    "\n",
    "test_df_LL = test_df.loc[:,'LONGITUDE':'LATITUDE']\n",
    "test_y = np.asarray(test_df_LL)\n",
    "#model.fit(input_data,train_y,nb_epoch=200,batch_size=128,callbacks=[\n",
    "       #ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1, min_delta=1e-4, mode='min')\n",
    "#,EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=5, mode='min', baseline=None, restore_best_weights=True)])\n",
    "#test_pred_y = model.predict([test_id, test_rssi, test_building_id])\n",
    "#test_pred_y = test_pred_y * ranges + bias \n",
    "#error_analysis(test_y, test_pred_y)\n",
    "\"\"\"one hot encode the dummy_labels.\n",
    "this is done because dummy_labels is a dataframe with the labels (BUILDINGID+FLOOR) \n",
    "as the column names\n",
    "\"\"\"\n",
    "#train_X,train_y, val_X, val_y = train_val_split(train_AP_features,train_labels)\n",
    "\n",
    "#Turn the given validation set into a testing set\n",
    "#test_df = pd.read_csv(path_validation,header = 0)\n",
    "#test_AP_features = (np.asarray(test_df.loc[:,'WAP001':'WAP520']))/200+0.5\n",
    "#test_labels = np.asarray(test_df[\"BUILDINGID\"].map(str) + test_df[\"FLOOR\"].map(str))\n",
    "#test_labels = np.asarray(pd.get_dummies(test_labels))\n",
    "#input_size = 520"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio: 0.1\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_13 (InputLayer)           [(None, 16)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)         (None, 16, 40)       20800       input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_14 (InputLayer)           [(None, 16)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 16, 40)       160         embedding_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 16)           64          input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 640)          0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 640)          10880       batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 1280)         0           flatten_8[0][0]                  \n",
      "                                                                 dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 1280)         5120        concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 1280)         0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 256)          327936      dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 256)          0           dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 256)          1024        dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "input_15 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 128)          32896       batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_9 (Embedding)         (None, 1, 1)         13          input_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 128)          0           dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)             (None, 1)            0           embedding_9[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 64)           8256        dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 1)            4           flatten_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 65)           0           dense_23[0][0]                   \n",
      "                                                                 batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 16)           1056        concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "xy (Dense)                      (None, 2)            34          dense_24[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 408,243\n",
      "Trainable params: 405,057\n",
      "Non-trainable params: 3,186\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2029 samples\n",
      "Epoch 1/5\n",
      "2029/2029 [==============================] - 1s 628us/sample - loss: 0.4383 - mse: 0.4383\n",
      "Epoch 2/5\n",
      "2029/2029 [==============================] - 0s 105us/sample - loss: 0.1108 - mse: 0.1108\n",
      "Epoch 3/5\n",
      "2029/2029 [==============================] - 0s 104us/sample - loss: 0.0625 - mse: 0.0625\n",
      "Epoch 4/5\n",
      "2029/2029 [==============================] - 0s 103us/sample - loss: 0.0450 - mse: 0.0450\n",
      "Epoch 5/5\n",
      "2029/2029 [==============================] - 0s 98us/sample - loss: 0.0379 - mse: 0.0379\n",
      "ratio =  0.1\n",
      "for 5 epochs, the total time cost is 8.360394\n",
      "for 5 epochs, the average time cost is 1.6720788\n",
      "ratio: 0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_16 (InputLayer)           [(None, 16)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_10 (Embedding)        (None, 16, 40)       20800       input_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_17 (InputLayer)           [(None, 16)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 16, 40)       160         embedding_10[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 16)           64          input_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)            (None, 640)          0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 640)          10880       batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 1280)         0           flatten_10[0][0]                 \n",
      "                                                                 dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 1280)         5120        concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 1280)         0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 256)          327936      dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 256)          0           dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 256)          1024        dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "input_18 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 128)          32896       batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_11 (Embedding)        (None, 1, 1)         13          input_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 128)          0           dense_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)            (None, 1)            0           embedding_11[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 64)           8256        dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 1)            4           flatten_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 65)           0           dense_28[0][0]                   \n",
      "                                                                 batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 16)           1056        concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "xy (Dense)                      (None, 2)            34          dense_29[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 408,243\n",
      "Trainable params: 405,057\n",
      "Non-trainable params: 3,186\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6006 samples\n",
      "Epoch 1/5\n",
      "6006/6006 [==============================] - 2s 302us/sample - loss: 0.1159 - mse: 0.1159\n",
      "Epoch 2/5\n",
      "6006/6006 [==============================] - 1s 104us/sample - loss: 0.0337 - mse: 0.0337\n",
      "Epoch 3/5\n",
      "6006/6006 [==============================] - 1s 100us/sample - loss: 0.0207 - mse: 0.0207\n",
      "Epoch 4/5\n",
      "6006/6006 [==============================] - 1s 93us/sample - loss: 0.0155 - mse: 0.0155\n",
      "Epoch 5/5\n",
      "6006/6006 [==============================] - 1s 104us/sample - loss: 0.0125 - mse: 0.0125\n",
      "ratio =  0.3\n",
      "for 5 epochs, the total time cost is 17.370281000000006\n",
      "for 5 epochs, the average time cost is 3.474056200000001\n",
      "ratio: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_19 (InputLayer)           [(None, 16)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_12 (Embedding)        (None, 16, 40)       20800       input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_20 (InputLayer)           [(None, 16)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 16, 40)       160         embedding_12[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 16)           64          input_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_12 (Flatten)            (None, 640)          0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 640)          10880       batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 1280)         0           flatten_12[0][0]                 \n",
      "                                                                 dense_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 1280)         5120        concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 1280)         0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 256)          327936      dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 256)          0           dense_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 256)          1024        dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "input_21 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_32 (Dense)                (None, 128)          32896       batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_13 (Embedding)        (None, 1, 1)         13          input_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 128)          0           dense_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_13 (Flatten)            (None, 1)            0           embedding_13[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_33 (Dense)                (None, 64)           8256        dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 1)            4           flatten_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 65)           0           dense_33[0][0]                   \n",
      "                                                                 batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_34 (Dense)                (None, 16)           1056        concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "xy (Dense)                      (None, 2)            34          dense_34[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 408,243\n",
      "Trainable params: 405,057\n",
      "Non-trainable params: 3,186\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9813 samples\n",
      "Epoch 1/5\n",
      "9813/9813 [==============================] - 2s 214us/sample - loss: 0.1782 - mse: 0.1782\n",
      "Epoch 2/5\n",
      "9813/9813 [==============================] - 1s 97us/sample - loss: 0.0281 - mse: 0.0281\n",
      "Epoch 3/5\n",
      "9813/9813 [==============================] - 1s 97us/sample - loss: 0.0188 - mse: 0.0188\n",
      "Epoch 4/5\n",
      "9813/9813 [==============================] - 1s 105us/sample - loss: 0.0141 - mse: 0.0141\n",
      "Epoch 5/5\n",
      "9813/9813 [==============================] - 1s 97us/sample - loss: 0.0110 - mse: 0.0110\n",
      "ratio =  0.5\n",
      "for 5 epochs, the total time cost is 23.825075999999996\n",
      "for 5 epochs, the average time cost is 4.765015199999999\n",
      "ratio: 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_22 (InputLayer)           [(None, 16)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_14 (Embedding)        (None, 16, 40)       20800       input_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_23 (InputLayer)           [(None, 16)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 16, 40)       160         embedding_14[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 16)           64          input_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_14 (Flatten)            (None, 640)          0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_35 (Dense)                (None, 640)          10880       batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 1280)         0           flatten_14[0][0]                 \n",
      "                                                                 dense_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 1280)         5120        concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 1280)         0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_36 (Dense)                (None, 256)          327936      dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 256)          0           dense_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 256)          1024        dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "input_24 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_37 (Dense)                (None, 128)          32896       batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_15 (Embedding)        (None, 1, 1)         13          input_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 128)          0           dense_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_15 (Flatten)            (None, 1)            0           embedding_15[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_38 (Dense)                (None, 64)           8256        dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 1)            4           flatten_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 65)           0           dense_38[0][0]                   \n",
      "                                                                 batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_39 (Dense)                (None, 16)           1056        concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "xy (Dense)                      (None, 2)            34          dense_39[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 408,243\n",
      "Trainable params: 405,057\n",
      "Non-trainable params: 3,186\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14050 samples\n",
      "Epoch 1/5\n",
      "14050/14050 [==============================] - 3s 178us/sample - loss: 0.0862 - mse: 0.0862\n",
      "Epoch 2/5\n",
      "14050/14050 [==============================] - 1s 92us/sample - loss: 0.0180 - mse: 0.0180\n",
      "Epoch 3/5\n",
      "14050/14050 [==============================] - 1s 93us/sample - loss: 0.0115 - mse: 0.0115\n",
      "Epoch 4/5\n",
      "14050/14050 [==============================] - 1s 101us/sample - loss: 0.0083 - mse: 0.0083\n",
      "Epoch 5/5\n",
      "14050/14050 [==============================] - 1s 102us/sample - loss: 0.0067 - mse: 0.0067\n",
      "ratio =  0.7\n",
      "for 5 epochs, the total time cost is 32.47601900000001\n",
      "for 5 epochs, the average time cost is 6.495203800000001\n",
      "ratio: 0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_25 (InputLayer)           [(None, 16)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_16 (Embedding)        (None, 16, 40)       20800       input_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_26 (InputLayer)           [(None, 16)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 16, 40)       160         embedding_16[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 16)           64          input_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_16 (Flatten)            (None, 640)          0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_40 (Dense)                (None, 640)          10880       batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 1280)         0           flatten_16[0][0]                 \n",
      "                                                                 dense_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 1280)         5120        concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 1280)         0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_41 (Dense)                (None, 256)          327936      dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 256)          0           dense_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 256)          1024        dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "input_27 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_42 (Dense)                (None, 128)          32896       batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_17 (Embedding)        (None, 1, 1)         13          input_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 128)          0           dense_42[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_17 (Flatten)            (None, 1)            0           embedding_17[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_43 (Dense)                (None, 64)           8256        dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 1)            4           flatten_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 65)           0           dense_43[0][0]                   \n",
      "                                                                 batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_44 (Dense)                (None, 16)           1056        concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "xy (Dense)                      (None, 2)            34          dense_44[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 408,243\n",
      "Trainable params: 405,057\n",
      "Non-trainable params: 3,186\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17904 samples\n",
      "Epoch 1/5\n",
      "17904/17904 [==============================] - 3s 170us/sample - loss: 0.0697 - mse: 0.0697\n",
      "Epoch 2/5\n",
      "17904/17904 [==============================] - 2s 90us/sample - loss: 0.0154 - mse: 0.0154\n",
      "Epoch 3/5\n",
      "17904/17904 [==============================] - 2s 92us/sample - loss: 0.0097 - mse: 0.0097\n",
      "Epoch 4/5\n",
      "17904/17904 [==============================] - 2s 107us/sample - loss: 0.0071 - mse: 0.0071\n",
      "Epoch 5/5\n",
      "17904/17904 [==============================] - 2s 103us/sample - loss: 0.0056 - mse: 0.0056\n",
      "ratio =  0.9\n",
      "for 5 epochs, the total time cost is 40.43242700000002\n",
      "for 5 epochs, the average time cost is 8.086485400000004\n",
      "ratio: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_28 (InputLayer)           [(None, 16)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_18 (Embedding)        (None, 16, 40)       20800       input_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_29 (InputLayer)           [(None, 16)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 16, 40)       160         embedding_18[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 16)           64          input_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_18 (Flatten)            (None, 640)          0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_45 (Dense)                (None, 640)          10880       batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 1280)         0           flatten_18[0][0]                 \n",
      "                                                                 dense_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 1280)         5120        concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 1280)         0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_46 (Dense)                (None, 256)          327936      dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 256)          0           dense_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 256)          1024        dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "input_30 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_47 (Dense)                (None, 128)          32896       batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_19 (Embedding)        (None, 1, 1)         13          input_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 128)          0           dense_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_19 (Flatten)            (None, 1)            0           embedding_19[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_48 (Dense)                (None, 64)           8256        dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 1)            4           flatten_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 65)           0           dense_48[0][0]                   \n",
      "                                                                 batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_49 (Dense)                (None, 16)           1056        concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "xy (Dense)                      (None, 2)            34          dense_49[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 408,243\n",
      "Trainable params: 405,057\n",
      "Non-trainable params: 3,186\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19937 samples\n",
      "Epoch 1/5\n",
      "19937/19937 [==============================] - 3s 168us/sample - loss: 0.0958 - mse: 0.0958\n",
      "Epoch 2/5\n",
      "19937/19937 [==============================] - 2s 91us/sample - loss: 0.0182 - mse: 0.0182\n",
      "Epoch 3/5\n",
      "19937/19937 [==============================] - 2s 97us/sample - loss: 0.0114 - mse: 0.0114\n",
      "Epoch 4/5\n",
      "19937/19937 [==============================] - 2s 101us/sample - loss: 0.0079 - mse: 0.0079\n",
      "Epoch 5/5\n",
      "19937/19937 [==============================] - 2s 108us/sample - loss: 0.0064 - mse: 0.0064\n",
      "ratio =  1\n",
      "for 5 epochs, the total time cost is 45.129733000000016\n",
      "for 5 epochs, the average time cost is 9.025946600000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def train_val_split(xs, y,ratio):\n",
    "    new_xs = []\n",
    "    new_y = []\n",
    "    train_val_split = np.random.rand(len(y))\n",
    "    train_val_split = train_val_split < ratio #should contain ~70% percent true\n",
    "    for x in xs:\n",
    "        x = x[train_val_split]\n",
    "        new_xs.append(x)\n",
    "    y = y[train_val_split]\n",
    "    new_y.append(y)\n",
    "    return new_xs, new_y\n",
    "test = [0.1,0.3,0.5,0.7,0.9,1]\n",
    "import pickle\n",
    "import time\n",
    "for i in test:\n",
    "    ratio = i * 1\n",
    "    part_train_x, part_train_y = train_val_split(input_data, train_y, ratio) \n",
    "    print(\"ratio: \"+ str(i)) \n",
    "    model = mlp(part_train_x)\n",
    "    #model.compile(optimizer=tf.optimizers.Adam(lr=0.001), loss='mse', metrics=['mse'])\n",
    "    start = time.clock()\n",
    "    model.fit(part_train_x,part_train_y,nb_epoch=5,batch_size=128,verbose = 1)\n",
    "    end = time.clock()\n",
    "    t = end-start\n",
    "    print(\"ratio = \", ratio)\n",
    "    print(\"for 5 epochs, the total time cost is\", t)\n",
    "    print(\"for 5 epochs, the average time cost is\", t/5)\n",
    "    # test_pred_y = model.predict([test_id, test_rssi, test_building_id])\n",
    "    # test_pred_y = test_pred_y * ranges + bias \n",
    "    # error_analysis(test_y, test_pred_y)\n",
    "    # fileName = '2cnn_lstm_dropout_layer_result_' + str(ratio)+ '.txt'\n",
    "    # print(\"writing to file name: \", fileName)\n",
    "    # file = open(fileName,'wb')\n",
    "    # pickle.dump(test_pred_y,file)\n",
    "    # file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "train_id = np.argsort(train_AP_features)[:,0:520]\n",
    "train_rssi = np.array(train_AP_features)[:,0:520]\n",
    "test_id = np.argsort(test_AP_features)[:,0:520]\n",
    "test_rssi = np.sort(test_AP_features)[:,0:520]\n",
    "input_data = np.concatenate((train_id, train_rssi), axis=1)\n",
    "test_data = np.concatenate((test_id, test_rssi), axis=1)\n",
    "train_floor_building = np.concatenate((train_building_id, floor_id), axis=1)\n",
    "print(train_floor_building.shape)\n",
    "test_floor_building = np.concatenate((test_building_id, test_floor_id), axis=1)\n",
    "print(test_floor_building.shape)\n",
    "\n",
    "knn_cate = neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "knn_cate.fit(input_data, train_floor_building)\n",
    "print(knn_cate.predict(test_data[0]))\n",
    "# print(knn_cate.score(test_data, test_floor_building))\n",
    "\n",
    "# # input_data = np.concatenate((train_id, train_rssi, train_building_id), axis=1)\n",
    "# input_data = np.concatenate((train_id, train_rssi), axis=1)\n",
    "# print(input_data.shape)\n",
    "# # test_data = np.concatenate((test_id, test_rssi, test_building_id), axis=1)\n",
    "# test_data = np.concatenate((test_id, test_rssi), axis=1)\n",
    "# n_neighbors = 5\n",
    "# knn = neighbors.KNeighborsRegressor(n_neighbors, weights='distance')\n",
    "# knn.fit(input_data[0:-1], train_y[0:-1])\n",
    "# pred_y = knn.predict(test_data)\n",
    "# # print(knn.score(input_data, train_y))\n",
    "# print(pred_y[0])\n",
    "# print(ranges)\n",
    "# print(bias)\n",
    "# print(test_y[0])\n",
    "# test_pred_y = pred_y * ranges + bias \n",
    "# print(test_pred_y[0])\n",
    "# error_analysis(test_y, test_pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-55b36643e917>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mneighbors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrain_rssi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_AP_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mtest_rssi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_AP_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# input_data = np.concatenate((train_id, train_rssi, train_building_id), axis=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "def train_val_split(x, y,ratio):\n",
    "    new_y = []\n",
    "    train_val_split = np.random.rand(len(y))\n",
    "    train_val_split = train_val_split < ratio #should contain ~70% percent true\n",
    "    x = x[train_val_split]\n",
    "    y = y[train_val_split]\n",
    "    return x, y\n",
    "test = [1]\n",
    "from sklearn import neighbors\n",
    "train_rssi = np.array(train_AP_features)\n",
    "test_rssi = np.array(test_AP_features)\n",
    "# input_data = np.concatenate((train_id, train_rssi, train_building_id), axis=1)\n",
    "input_data = train_rssi\n",
    "print(input_data.shape)\n",
    "# test_data = np.concatenate((test_id, test_rssi, test_building_id), axis=1)\n",
    "test_data = test_rssi\n",
    "test = [0.1, 0.3,0.5,0.7,0.9,1.05]\n",
    "for i in test:\n",
    "    ratio = i * 0.1\n",
    "    part_train_x,part_train_y = train_val_split(input_data, train_y, ratio) \n",
    "    print(\"ratio: \"+ str(i)) \n",
    "    #model = lstm(part_train_x)\n",
    "    #model.compile(optimizer=tf.optimizers.Adam(lr=0.001), loss='mse', metrics=['mse'])\n",
    "    #start = time.clock()\n",
    "    #model.fit(part_train_x,part_train_y,nb_epoch=5,batch_size=128,verbose = 1)\n",
    "    #end = time.clock()\n",
    "    #t = end-start\n",
    "    #print(\"ratio = \", ratio)\n",
    "    #print(\"for 5 epochs, the total time cost is\", t)\n",
    "    #print(\"for 5 epochs, the average time cost is\", t/5)\n",
    "    n_neighbors = 5\n",
    "    knn = neighbors.KNeighborsRegressor(n_neighbors, weights='distance')\n",
    "    knn.fit( part_train_x, part_train_y)\n",
    "    pred_y = knn.predict(test_data)\n",
    "    # print(knn.score(input_data, train_y))\n",
    "    test_pred_y = pred_y * ranges + bias \n",
    "    print(test_pred_y[0])\n",
    "    error_analysis(test_y, test_pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pickle\n",
    "model = cnn_lstm(input_data)\n",
    "# for i in range(50):\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=\"checkpoints\\\\\"+\"CNN_Res_lstm3layer\"+\"epoch{epoch:3d}-loss{loss:3f}.h5\", monitor=\"loss\")\n",
    "    \n",
    "    #model.compile(optimizer=tf.optimizers.Adam(lr=0.001), loss='mse', metrics=['mse'])\n",
    "model.fit(input_data,train_y,nb_epoch=300,batch_size=128,verbose = 1, callbacks=[model_checkpoint_callback] )\n",
    "model.save(\"CNN_Res_lstm_3.h5\")\n",
    "test_pred_y = model.predict([test_id, test_rssi, test_building_id])\n",
    "test_pred_y = test_pred_y * ranges + bias \n",
    "error_analysis(test_y, test_pred_y)\n",
    "file = open('CNN_Res3_lstm_5layer_result.txt','wb')\n",
    "pickle.dump(test_pred_y,file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(path_validation,header = 0)\n",
    "print(test_df.head(2))\n",
    "test_AP_strengths =test_df.loc[:,'WAP001':'WAP520']\n",
    "#test_AP_features = np.array(test_AP_strengths.replace([100], [-100]))\n",
    "test_building_ids_str = test_df[\"BUILDINGID\"].map(str) #convert all the building ids to strings\n",
    "test_building_floors_str = test_df[\"FLOOR\"].map(str) #convert all the building floors to strings\n",
    "#print(id_label)\n",
    "test_floor_enc = LabelEncoder()\n",
    "test_floor_enc.fit(building_floors_str)\n",
    "test_floor_id = test_floor_enc.transform(test_building_floors_str)\n",
    "test_floor_id = test_floor_id.reshape(-1,1)\n",
    "print(\"test floor id\",(test_floor_id.shape))\n",
    "test_building_enc = LabelEncoder()\n",
    "test_building_enc.fit(test_building_ids_str)\n",
    "test_building_id = test_building_enc.transform(test_building_ids_str)\n",
    "test_building_id = test_building_id.reshape(-1,1)\n",
    "print(\"test building id:\",(test_building_id.shape))\n",
    "test_AP_features = np.array(test_AP_strengths.replace([100],[-100]))\n",
    "test_id = np.argsort(test_AP_features)[:,500:520]\n",
    "test_rssi = np.sort(test_AP_features)[:,500:520]\n",
    "\n",
    "test_rssi_floor = np.hstack((test_rssi,test_floor_id))\n",
    "print(test_rssi_floor[0], test_rssi_floor.shape)\n",
    "\n",
    "test_df_LL = test_df.loc[:,'LONGITUDE':'LATITUDE']\n",
    "test_y = np.asarray(test_df_LL)\n",
    "test_pred_y = model.predict([test_id, test_rssi, test_building_id])\n",
    "test_pred_y = test_pred_y * ranges + bias \n",
    "error_analysis(test_y, test_pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
