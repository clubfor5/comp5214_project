{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/zhangzheng/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/zhangzheng/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/zhangzheng/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/zhangzheng/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/zhangzheng/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/zhangzheng/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/zhangzheng/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/zhangzheng/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/zhangzheng/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/zhangzheng/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/zhangzheng/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/zhangzheng/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam,sgd\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import scale\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "import tensorflow.keras.layers as L\n",
    "import tensorflow.keras.models as M\n",
    "import tensorflow.keras.backend as K\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import scipy.stats as stats\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import math\n",
    "import glob\n",
    "import pickle\n",
    "import random\n",
    "import os\n",
    "\n",
    "\n",
    "#train_files,test_files = get_data_files()\n",
    "#print(train_files)\n",
    "def train_val_split(train_AP_features,train_labels,fp_ratio):\n",
    "    #generate len(train_AP_features) of floats in between 0 and 1\n",
    "    train_val_split = np.random.rand(len(train_AP_features))\n",
    "    #convert train_val_split to an array of booleans: if elem < 0.7 = true, else: false\n",
    "    train_val_split = train_val_split < fp_ratio #should contain ~70% percent true\n",
    "    # We will then split our given training set into training + validation \n",
    "    train_X = train_AP_features[train_val_split]\n",
    "    train_y = train_labels[train_val_split]\n",
    "    val_X = train_AP_features[~train_val_split]\n",
    "    val_y = train_labels[~train_val_split]\n",
    "    return train_X,train_y, val_X, val_y\n",
    "\n",
    "def normalization(data):\n",
    "    minVals = data.min(0)\n",
    "    maxVals = data.max(0)\n",
    "    ranges = maxVals - minVals\n",
    "    normData = (data - minVals)/ranges\n",
    "    return normData,ranges,minVals\n",
    "\n",
    "def load_data(file_name):\n",
    "    df = pd.read_csv(file_name,header = 0)\n",
    "    #print(df.head(2))\n",
    "    AP_strengths = df.loc[:,'WAP001':'WAP520']\n",
    "    AP_strengths = AP_strengths.replace([100], [-100])\n",
    "    print(AP_strengths.head(2))\n",
    "    df_xy = df.loc[:,'LONGITUDE':'LATITUDE']\n",
    "    labels = np.asarray(df_xy)\n",
    "    AP_features = (np.asarray(AP_strengths))\n",
    "    \n",
    "    building_ids_str = df[\"BUILDINGID\"].map(str) #convert all the building ids to strings\n",
    "    building_floors_str = df[\"FLOOR\"].map(str) #convert all the building floors to strings\n",
    "    return AP_features, building_ids_str, building_floors_str, labels\n",
    "\n",
    "\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "    return math.sqrt((y_true[0]-y_pred[0])**2+(y_true[1]-y_pred[1])**2)\n",
    "\n",
    "\n",
    "def rms(list):\n",
    "    sum = 0\n",
    "    for term in list:\n",
    "        sum+= term*term\n",
    "    rms = math.sqrt(sum / len(list))\n",
    "    return rms\n",
    "def save_to_log(file_name,preds_pos):\n",
    "    write_file = open(file_name,'w')\n",
    "    for pos in preds_pos:\n",
    "        line = str(pos[0])+','+str(pos[1])+'\\n'\n",
    "        write_file.write(line)\n",
    "    return \n",
    "def load_log(file_name):\n",
    "    read_file = open(file_name,'r')\n",
    "    lines = read_file.readlines()\n",
    "    pred_pos = []\n",
    "    for line in lines:\n",
    "        pos = line.split(',')\n",
    "        x = float(pos[0])\n",
    "        y = float(pos[1])\n",
    "        pred_pos.append([x,y])\n",
    "    return pred_pos\n",
    "\n",
    "def cdf(error):\n",
    "    count = len(error)\n",
    "    cdf_y = [i/count for i in range(count)]\n",
    "    error_sorted = sorted(error)\n",
    "    plt.xlim(0,50)\n",
    "    plt.ylim(0,1)\n",
    "    plt.plot(error_sorted, cdf_y)\n",
    "    plt.show()\n",
    "    return cdf_y,error_sorted\n",
    "\n",
    "def error_analysis(pred_y,true_y):\n",
    "    error =np.sqrt((pred_y[:,0]-true_y[:,0])**2+(pred_y[:,1]-true_y[:,1])**2)\n",
    "    rms_error = rms(error)\n",
    "    print('rms_error:', rms_error)\n",
    "    mean_error = sum(error)/len(error)\n",
    "    print('mean_error:', mean_error)\n",
    "    print(\"generating cdf:\")\n",
    "    cdf_y,error_sorted = cdf(error)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   WAP001  WAP002  WAP003  WAP004  WAP005  WAP006  WAP007  WAP008  WAP009  \\\n",
      "0    -100    -100    -100    -100    -100    -100    -100    -100    -100   \n",
      "1    -100    -100    -100    -100    -100    -100    -100    -100    -100   \n",
      "\n",
      "   WAP010  ...  WAP511  WAP512  WAP513  WAP514  WAP515  WAP516  WAP517  \\\n",
      "0    -100  ...    -100    -100    -100    -100    -100    -100    -100   \n",
      "1    -100  ...    -100    -100    -100    -100    -100    -100    -100   \n",
      "\n",
      "   WAP518  WAP519  WAP520  \n",
      "0    -100    -100    -100  \n",
      "1    -100    -100    -100  \n",
      "\n",
      "[2 rows x 520 columns]\n"
     ]
    }
   ],
   "source": [
    "AP_features, building_ids_str, building_floors_str, labels = load_data('trainingData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### input: \n",
    "def mlp_regression():\n",
    "    model1 = Sequential()\n",
    "    model1.add(Dense(512, input_dim=input_size, activation='relu', bias=True))\n",
    "    model1.add(Dense(512, activation='relu', bias=True))\n",
    "    model1.add(Dense(128, activation='relu', bias=True))\n",
    "    model1.add(Dense(128, activation='relu', bias=True))\n",
    "    model1.add(Dense(32, activation='relu', bias=True))\n",
    "    model1.add(Dense(2, activation='sigmoid', bias=True))\n",
    "    #model1.compile(optimizer='sgd', loss=[mean_squared_error_index],metrics=[mean_squared_error_index])\n",
    "    return model1    \n",
    "\n",
    "def mlp(input_data):\n",
    "    wapid_dim = input_data[0].shape[1]\n",
    "    wapid_input_layer = L.Input(shape=(wapid_dim,))\n",
    "    wap_emb = L.Embedding(520,40)(wapid_input_layer)\n",
    "    wap_emb = L.BatchNormalization()(wap_emb)\n",
    "    wap_emb = L.Flatten()(wap_emb)\n",
    "    \n",
    "    rssi_f_dim = input_data[1].shape[1]\n",
    "    rssi_f_input_layer = L.Input(shape=(rssi_f_dim,))\n",
    "    rssi_f = L.BatchNormalization()(rssi_f_input_layer)\n",
    "    rssi_f_feature = L.Dense(16*40, activation='relu')(rssi_f)\n",
    "    \n",
    "    \n",
    "    input_site_layer = L.Input(shape=(1,))\n",
    "    site_emb = L.Embedding(13, 1)(input_site_layer)\n",
    "    site_emb = L.Flatten()(site_emb)\n",
    "    site_emb = L.BatchNormalization()(site_emb)\n",
    "    x = L.Concatenate(axis=1)([wap_emb, rssi_f_feature])\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.Dropout(0.1)(x)\n",
    "    x = L.Dense(256, activation='relu')(x)\n",
    "    x = L.Dropout(0.2)(x)\n",
    "    #x = L.Reshape((-1, 1))(x)\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.Dense(128,activation='relu')(x)\n",
    "    x = L.Dropout(0.1)(x)\n",
    "    x = L.Dense(64, activation='relu')(x)\n",
    "    x = L.Concatenate(axis=1)([x,site_emb])\n",
    "    x = L.Dense(16, activation='relu')(x)\n",
    "    #x = L.Dropout(0.1)(x)\n",
    "    output_layer_1 = L.Dense(2, name='xy')(x)\n",
    "    model = M.Model([wapid_input_layer, rssi_f_input_layer, input_site_layer], [output_layer_1])\n",
    "    model.compile(optimizer=tf.optimizers.Adam(lr=0.001), loss='mse', metrics=['mse'])\n",
    "    model.summary()\n",
    "    return model\n",
    "def lstm(input_data):\n",
    "    wapid_dim = input_data[0].shape[1]\n",
    "    wapid_input_layer = L.Input(shape=(wapid_dim,))\n",
    "    wap_emb = L.Embedding(520,40)(wapid_input_layer)\n",
    "    wap_emb = L.BatchNormalization()(wap_emb)\n",
    "    wap_emb = L.Flatten()(wap_emb)\n",
    "    \n",
    "    rssi_f_dim = input_data[1].shape[1]\n",
    "    rssi_f_input_layer = L.Input(shape=(rssi_f_dim,))\n",
    "    rssi_f = L.BatchNormalization()(rssi_f_input_layer)\n",
    "    rssi_f_feature = L.Dense(16*40, activation='relu')(rssi_f)\n",
    "    \n",
    "    \n",
    "    input_site_layer = L.Input(shape=(1,))\n",
    "    site_emb = L.Embedding(13, 1)(input_site_layer)\n",
    "    site_emb = L.Flatten()(site_emb)\n",
    "    site_emb = L.BatchNormalization()(site_emb)\n",
    "    x = L.Concatenate(axis=1)([wap_emb, rssi_f_feature])\n",
    "    x = L.BatchNormalization()(x)\n",
    "    #x = L.Dropout(0.2)(x)\n",
    "    #x = L.Dense(256, activation='relu')(x)\n",
    "    x = L.Dropout(0.1)(x)\n",
    "    x = L.Dense(128, activation='relu')(x)\n",
    "    #x = L.Dropout(0.2)(x)\n",
    "    x = L.Reshape((-1, 1))(x)\n",
    "    print(x.shape)\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.LSTM(128, dropout=0.1, recurrent_dropout=0, return_sequences=True, activation='sigmoid')(x)\n",
    "    x = L.LSTM(64, dropout=0.1, return_sequences=False, activation='sigmoid')(x)\n",
    "    #x = L.Dense(128,activation='relu')(x)\n",
    "    #x = L.Dropout(0.2)(x)\n",
    "    #x = L.Reshape((-1, 1))(x)\n",
    "    x = L.Dense(64, activation='relu')(x)\n",
    "    #x = L.LSTM(16, dropout=0, return_sequences=False, activation='relu')(x)\n",
    "    x = L.Concatenate(axis=1)([x,site_emb])\n",
    "    x = L.Dense(16, activation='relu')(x)\n",
    "    #x = L.Dropout(0.1)(x)\n",
    "    output_layer_1 = L.Dense(2, name='xy')(x)\n",
    "    model = M.Model([wapid_input_layer, rssi_f_input_layer, input_site_layer], [output_layer_1])\n",
    "    model.compile(optimizer=tf.optimizers.Adam(lr=0.001), loss='mse', metrics=['mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   WAP001  WAP002  WAP003  WAP004  WAP005  WAP006  WAP007  WAP008  WAP009  \\\n",
      "0     100     100     100     100     100     100     100     100     100   \n",
      "1     100     100     100     100     100     100     100     100     100   \n",
      "\n",
      "   WAP010  ...  WAP520  LONGITUDE      LATITUDE  FLOOR  BUILDINGID  SPACEID  \\\n",
      "0     100  ...     100 -7541.2643  4.864921e+06      2           1      106   \n",
      "1     100  ...     100 -7536.6212  4.864934e+06      2           1      106   \n",
      "\n",
      "   RELATIVEPOSITION  USERID  PHONEID   TIMESTAMP  \n",
      "0                 2       2       23  1371713733  \n",
      "1                 2       2       23  1371713691  \n",
      "\n",
      "[2 rows x 529 columns]\n",
      "floor id (19937, 1)\n",
      "building id: (19937,)\n",
      "[-97 -94 -94 -94 -90 -90 -88 -88 -87 -86 -86 -84 -83 -83 -83 -80]\n",
      "[154  35 141 155  90  89 102 190 103 150 191 172 171   7 149 247]\n",
      "[[-150 -150 -150 ... -150 -150 -150]\n",
      " [-150 -150 -150 ... -150 -150 -150]\n",
      " [-150 -150 -150 ... -150 -150 -150]\n",
      " ...\n",
      " [-150 -150 -150 ... -150 -150 -150]\n",
      " [-150 -150 -150 ... -150 -150 -150]\n",
      " [-150 -150 -150 ... -150 -150 -150]]\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 16)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 16, 40)       20800       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 16)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 16, 40)       160         embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 16)           64          input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 640)          0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 640)          10880       batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1280)         0           flatten[0][0]                    \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 1280)         5120        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1280)         0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          327936      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 256)          1024        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          32896       batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 1)         13          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 128)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1)            0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 64)           8256        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 1)            4           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 65)           0           dense_3[0][0]                    \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 16)           1056        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "xy (Dense)                      (None, 2)            34          dense_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 408,243\n",
      "Trainable params: 405,057\n",
      "Non-trainable params: 3,186\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 16)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 16, 40)       20800       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 16)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 16, 40)       160         embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 16)           64          input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 640)          0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 640)          10880       batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1280)         0           flatten[0][0]                    \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 1280)         5120        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1280)         0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          327936      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 256)          1024        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          32896       batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 1)         13          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 128)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1)            0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 64)           8256        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 1)            4           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 65)           0           dense_3[0][0]                    \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 16)           1056        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "xy (Dense)                      (None, 2)            34          dense_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 408,243\n",
      "Trainable params: 405,057\n",
      "Non-trainable params: 3,186\n",
      "__________________________________________________________________________________________________\n",
      "[  -7691.3384     4864745.74501597] [390.51940991 270.94278403]\n",
      "   WAP001  WAP002  WAP003  WAP004  WAP005  WAP006  WAP007  WAP008  WAP009  \\\n",
      "0     100     100     100     100     100     100     100     100     100   \n",
      "1     100     100     100     100     100     100     100     100     100   \n",
      "\n",
      "   WAP010  ...  WAP520    LONGITUDE      LATITUDE  FLOOR  BUILDINGID  SPACEID  \\\n",
      "0     100  ...     100 -7515.916799  4.864890e+06      1           1        0   \n",
      "1     100  ...     100 -7383.867221  4.864840e+06      4           2        0   \n",
      "\n",
      "   RELATIVEPOSITION  USERID  PHONEID   TIMESTAMP  \n",
      "0                 0       0        0  1380872703  \n",
      "1                 0       0       13  1381155054  \n",
      "\n",
      "[2 rows x 529 columns]\n",
      "test floor id (1111, 1)\n",
      "test building id: (1111, 1)\n",
      "[-150 -150 -150 -150 -150 -150 -150 -150 -150 -150 -150 -150 -150 -150\n",
      " -150  -91    1] (1111, 17)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'one hot encode the dummy_labels.\\nthis is done because dummy_labels is a dataframe with the labels (BUILDINGID+FLOOR) \\nas the column names\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#import tensorflow_addons as tfa\n",
    "#from tensorflow_addons.layers import WeightNormalization\n",
    "#from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "path_train = \"trainingData.csv\"\n",
    "path_validation = \"validationData.csv\"\n",
    "train_df = pd.read_csv(path_train,header = 0)\n",
    "print(train_df.head(2))\n",
    "\n",
    "train_AP_strengths =train_df.loc[:,'WAP001':'WAP520']\n",
    "#train_AP_features= np.array(train_AP_strengths.replace([100], [-100]))\n",
    "building_ids_str = train_df[\"BUILDINGID\"].map(str) #convert all the building ids to strings\n",
    "building_floors_str = train_df[\"FLOOR\"].map(str) #convert all the building floors to strings\n",
    "#print(id_label)\n",
    "floor_enc = LabelEncoder()\n",
    "floor_enc.fit(building_floors_str)\n",
    "floor_id = floor_enc.transform(building_floors_str)\n",
    "floor_id = floor_id.reshape(-1,1)\n",
    "print(\"floor id\",(floor_id.shape))\n",
    "building_enc = LabelEncoder()\n",
    "building_enc.fit(building_ids_str)\n",
    "building_id = building_enc.transform(building_ids_str)\n",
    "train_building_id = building_id.reshape(-1,1)\n",
    "print(\"building id:\",(building_id.shape))\n",
    "\n",
    "train_AP_features = np.array(train_AP_strengths.replace([100],[-150]))\n",
    "##### 1) RSSI_FLOOR 2) SSID 3) BUILDING_ID\n",
    "train_id = np.argsort(train_AP_features)[:,504:520]\n",
    "train_rssi = np.sort(train_AP_features)[:,504:520]\n",
    "print(train_rssi[10])\n",
    "print(train_id[10])\n",
    "print(train_AP_features[train_id[10]])\n",
    "#train_rssi_floor = np.hstack((train_rssi,floor_id))\n",
    "#print(train_rssi_floor[0], train_rssi_floor.shape)\n",
    "#print(train_id[0],train_rssi[0],train_AP_features[0])\n",
    "\n",
    "input_data = [train_id, train_rssi, train_building_id]\n",
    "model = mlp(input_data)\n",
    "model.summary()\n",
    "\n",
    "train_df_LL = train_df.loc[:,'LONGITUDE':'LATITUDE']\n",
    "train_labels = np.asarray(train_df_LL)\n",
    "train_y,ranges,bias =  normalization(train_labels)\n",
    "print(bias,ranges)\n",
    "test_df = pd.read_csv(path_validation,header = 0)\n",
    "print(test_df.head(2))\n",
    "test_AP_strengths =test_df.loc[:,'WAP001':'WAP520']\n",
    "#test_AP_features = np.array(test_AP_strengths.replace([100], [-100]))\n",
    "test_building_ids_str = test_df[\"BUILDINGID\"].map(str) #convert all the building ids to strings\n",
    "test_building_floors_str = test_df[\"FLOOR\"].map(str) #convert all the building floors to strings\n",
    "#print(id_label)\n",
    "test_floor_enc = LabelEncoder()\n",
    "test_floor_enc.fit(building_floors_str)\n",
    "test_floor_id = test_floor_enc.transform(test_building_floors_str)\n",
    "test_floor_id = test_floor_id.reshape(-1,1)\n",
    "print(\"test floor id\",(test_floor_id.shape))\n",
    "test_building_enc = LabelEncoder()\n",
    "test_building_enc.fit(test_building_ids_str)\n",
    "test_building_id = test_building_enc.transform(test_building_ids_str)\n",
    "test_building_id = test_building_id.reshape(-1,1)\n",
    "print(\"test building id:\",(test_building_id.shape))\n",
    "test_AP_features = np.array(test_AP_strengths.replace([100],[-150]))\n",
    "test_id = np.argsort(test_AP_features)[:,504:520]\n",
    "test_rssi = np.sort(test_AP_features)[:,504:520]\n",
    "\n",
    "test_rssi_floor = np.hstack((test_rssi,test_floor_id))\n",
    "print(test_rssi_floor[0], test_rssi_floor.shape)\n",
    "\n",
    "test_df_LL = test_df.loc[:,'LONGITUDE':'LATITUDE']\n",
    "test_y = np.asarray(test_df_LL)\n",
    "#model.fit(input_data,train_y,nb_epoch=200,batch_size=128,callbacks=[\n",
    "       #ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1, min_delta=1e-4, mode='min')\n",
    "#,EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=5, mode='min', baseline=None, restore_best_weights=True)])\n",
    "#test_pred_y = model.predict([test_id, test_rssi, test_building_id])\n",
    "#test_pred_y = test_pred_y * ranges + bias \n",
    "#error_analysis(test_y, test_pred_y)\n",
    "\"\"\"one hot encode the dummy_labels.\n",
    "this is done because dummy_labels is a dataframe with the labels (BUILDINGID+FLOOR) \n",
    "as the column names\n",
    "\"\"\"\n",
    "#train_X,train_y, val_X, val_y = train_val_split(train_AP_features,train_labels)\n",
    "\n",
    "#Turn the given validation set into a testing set\n",
    "#test_df = pd.read_csv(path_validation,header = 0)\n",
    "#test_AP_features = (np.asarray(test_df.loc[:,'WAP001':'WAP520']))/200+0.5\n",
    "#test_labels = np.asarray(test_df[\"BUILDINGID\"].map(str) + test_df[\"FLOOR\"].map(str))\n",
    "#test_labels = np.asarray(pd.get_dummies(test_labels))\n",
    "#input_size = 520"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split(xs, y,ratio):\n",
    "    new_xs = []\n",
    "    new_y = []\n",
    "    train_val_split = np.random.rand(len(y))\n",
    "    train_val_split = train_val_split < ratio #should contain ~70% percent true\n",
    "    for x in xs:\n",
    "        x = x[train_val_split]\n",
    "        new_xs.append(x)\n",
    "    y = y[train_val_split]\n",
    "    new_y.append(y)\n",
    "    return new_xs, new_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio: 1\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 16)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 16, 40)       20800       input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            [(None, 16)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 40)       160         embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16)           64          input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 640)          0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 640)          10880       batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 1280)         0           flatten_4[0][0]                  \n",
      "                                                                 dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 1280)         5120        concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 1280)         0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 256)          327936      dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 256)          0           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 256)          1024        dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 128)          32896       batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 1, 1)         13          input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 128)          0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 1)            0           embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 64)           8256        dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 1)            4           flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 65)           0           dense_13[0][0]                   \n",
      "                                                                 batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 16)           1056        concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "xy (Dense)                      (None, 2)            34          dense_14[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 408,243\n",
      "Trainable params: 405,057\n",
      "Non-trainable params: 3,186\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "rms_error: 17.285614859220882\n",
      "mean_error: 14.238264530515986\n",
      "generating cdf:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing to file name:  mlp_dropout_layer_result_0.1.txt\n",
      "ratio: 2\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           [(None, 16)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 16, 40)       20800       input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_11 (InputLayer)           [(None, 16)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 16, 40)       160         embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16)           64          input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 640)          0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 640)          10880       batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 1280)         0           flatten_6[0][0]                  \n",
      "                                                                 dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 1280)         5120        concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 1280)         0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 256)          327936      dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 256)          0           dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 256)          1024        dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "input_12 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 128)          32896       batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, 1, 1)         13          input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 128)          0           dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 1)            0           embedding_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 64)           8256        dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 1)            4           flatten_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 65)           0           dense_18[0][0]                   \n",
      "                                                                 batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 16)           1056        concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "xy (Dense)                      (None, 2)            34          dense_19[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 408,243\n",
      "Trainable params: 405,057\n",
      "Non-trainable params: 3,186\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pickle\n",
    "for i in range(1,11):\n",
    "    ratio = i * 0.1\n",
    "    part_train_x, part_train_y = train_val_split(input_data, train_y, ratio) \n",
    "    print(\"ratio: \"+ str(i)) \n",
    "    model = mlp(part_train_x)\n",
    "    #model.compile(optimizer=tf.optimizers.Adam(lr=0.001), loss='mse', metrics=['mse'])\n",
    "    model.fit(part_train_x,part_train_y,nb_epoch=300,batch_size=128,verbose = 0)\n",
    "    test_pred_y = model.predict([test_id, test_rssi, test_building_id])\n",
    "    test_pred_y = test_pred_y * ranges + bias \n",
    "    error_analysis(test_y, test_pred_y)\n",
    "    fileName = 'mlp_dropout_layer_result_' + str(ratio)+ '.txt'\n",
    "    print(\"writing to file name: \", fileName)\n",
    "    file = open(fileName,'wb')\n",
    "    pickle.dump(test_pred_y,file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "\n",
    "    \n",
    "    #model.compile(optimizer=tf.optimizers.Adam(lr=0.001), loss='mse', metrics=['mse'])s\n",
    "    model.fit(input_data,train_y,nb_epoch=10,batch_size=128,verbose = 1)\n",
    "    test_pred_y = model.predict([test_id, test_rssi, test_building_id])\n",
    "    test_pred_y = test_pred_y * ranges + bias \n",
    "    error_analysis(test_y, test_pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(path_validation,header = 0)\n",
    "print(test_df.head(2))\n",
    "test_AP_strengths =test_df.loc[:,'WAP001':'WAP520']\n",
    "#test_AP_features = np.array(test_AP_strengths.replace([100], [-100]))\n",
    "test_building_ids_str = test_df[\"BUILDINGID\"].map(str) #convert all the building ids to strings\n",
    "test_building_floors_str = test_df[\"FLOOR\"].map(str) #convert all the building floors to strings\n",
    "#print(id_label)\n",
    "test_floor_enc = LabelEncoder()\n",
    "test_floor_enc.fit(building_floors_str)\n",
    "test_floor_id = test_floor_enc.transform(test_building_floors_str)\n",
    "test_floor_id = test_floor_id.reshape(-1,1)\n",
    "print(\"test floor id\",(test_floor_id.shape))\n",
    "test_building_enc = LabelEncoder()\n",
    "test_building_enc.fit(test_building_ids_str)\n",
    "test_building_id = test_building_enc.transform(test_building_ids_str)\n",
    "test_building_id = test_building_id.reshape(-1,1)\n",
    "print(\"test building id:\",(test_building_id.shape))\n",
    "test_AP_features = np.array(test_AP_strengths.replace([100],[-100]))\n",
    "test_id = np.argsort(test_AP_features)[:,500:520]\n",
    "test_rssi = np.sort(test_AP_features)[:,500:520]\n",
    "\n",
    "test_rssi_floor = np.hstack((test_rssi,test_floor_id))\n",
    "print(test_rssi_floor[0], test_rssi_floor.shape)\n",
    "\n",
    "test_df_LL = test_df.loc[:,'LONGITUDE':'LATITUDE']\n",
    "test_y = np.asarray(test_df_LL)\n",
    "test_pred_y = model.predict([test_id, test_rssi, test_building_id])\n",
    "test_pred_y = test_pred_y * ranges + bias \n",
    "error_analysis(test_y, test_pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.utils import np_utils\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "# define the raw dataset\n",
    "alphabet = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "# create mapping of characters to integers (0-25) and the reverse\n",
    "char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(alphabet))\n",
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 3\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, len(alphabet) - seq_length, 1):\n",
    "    seq_in = alphabet[i:i + seq_length]\n",
    "    seq_out = alphabet[i + seq_length]\n",
    "    dataX.append([char_to_int[char] for char in seq_in])\n",
    "    dataY.append(char_to_int[seq_out])\n",
    "    #print(seq_in, '->', seq_out)\n",
    "# reshape X to be [samples, time steps, features]\n",
    "X = numpy.reshape(dataX, (len(dataX), seq_length))\n",
    "print(X.shape)\n",
    "print(X[0])\n",
    "# normalize\n",
    "X = X / float(len(alphabet))\n",
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)\n",
    "# create and fit the model\n",
    "input_layer = L.Input(shape=(3,))\n",
    "input_layer1 = L.Reshape((1, -1))(input_layer)\n",
    "y = L.LSTM(32,return_sequences=False, activation='relu')(input_layer)\n",
    "output_layer_1 = L.Dense(1, name='output')(y)\n",
    "model = M.Model([input_layer], [output_layer_1])\n",
    "model.fit(X, y, epochs=500, batch_size=1, verbose=2)\n",
    "# summarize performance of the model\n",
    "scores = model.evaluate(X, y, verbose=0)\n",
    "print(\"Model Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "# demonstrate some model predictions\n",
    "for pattern in dataX:\n",
    "    x = numpy.reshape(pattern, (1, 1, len(pattern)))\n",
    "    x = x / float(len(alphabet))\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    print(seq_in, '->', seq_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
