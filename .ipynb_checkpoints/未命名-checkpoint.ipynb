{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/zhangzheng/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/zhangzheng/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/zhangzheng/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/zhangzheng/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/zhangzheng/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/zhangzheng/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/zhangzheng/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/zhangzheng/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/zhangzheng/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/zhangzheng/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/zhangzheng/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/zhangzheng/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam,sgd\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import scale\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "import tensorflow.keras.layers as L\n",
    "import tensorflow.keras.models as M\n",
    "import tensorflow.keras.backend as K\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import scipy.stats as stats\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import math\n",
    "import glob\n",
    "import pickle\n",
    "import random\n",
    "import os\n",
    "\n",
    "\n",
    "#train_files,test_files = get_data_files()\n",
    "#print(train_files)\n",
    "def train_val_split(train_AP_features,train_labels,fp_ratio):\n",
    "    #generate len(train_AP_features) of floats in between 0 and 1\n",
    "    train_val_split = np.random.rand(len(train_AP_features))\n",
    "    #convert train_val_split to an array of booleans: if elem < 0.7 = true, else: false\n",
    "    train_val_split = train_val_split < fp_ratio #should contain ~70% percent true\n",
    "    # We will then split our given training set into training + validation \n",
    "    train_X = train_AP_features[train_val_split]\n",
    "    train_y = train_labels[train_val_split]\n",
    "    val_X = train_AP_features[~train_val_split]\n",
    "    val_y = train_labels[~train_val_split]\n",
    "    return train_X,train_y, val_X, val_y\n",
    "\n",
    "def normalization(data):\n",
    "    minVals = data.min(0)\n",
    "    maxVals = data.max(0)\n",
    "    ranges = maxVals - minVals\n",
    "    normData = (data - minVals)/ranges\n",
    "    return normData,ranges,minVals\n",
    "\n",
    "def load_data(file_name):\n",
    "    df = pd.read_csv(file_name,header = 0)\n",
    "    #print(df.head(2))\n",
    "    AP_strengths = df.loc[:,'WAP001':'WAP520']\n",
    "    AP_strengths = AP_strengths.replace([100], [-100])\n",
    "    print(AP_strengths.head(2))\n",
    "    df_xy = df.loc[:,'LONGITUDE':'LATITUDE']\n",
    "    labels = np.asarray(df_xy)\n",
    "    AP_features = (np.asarray(AP_strengths))\n",
    "    \n",
    "    building_ids_str = df[\"BUILDINGID\"].map(str) #convert all the building ids to strings\n",
    "    building_floors_str = df[\"FLOOR\"].map(str) #convert all the building floors to strings\n",
    "    return AP_features, building_ids_str, building_floors_str, labels\n",
    "\n",
    "\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "    return math.sqrt((y_true[0]-y_pred[0])**2+(y_true[1]-y_pred[1])**2)\n",
    "\n",
    "\n",
    "def rms(list):\n",
    "    sum = 0\n",
    "    for term in list:\n",
    "        sum+= term*term\n",
    "    rms = math.sqrt(sum / len(list))\n",
    "    return rms\n",
    "def save_to_log(file_name,preds_pos):\n",
    "    write_file = open(file_name,'w')\n",
    "    for pos in preds_pos:\n",
    "        line = str(pos[0])+','+str(pos[1])+'\\n'\n",
    "        write_file.write(line)\n",
    "    return \n",
    "def load_log(file_name):\n",
    "    read_file = open(file_name,'r')\n",
    "    lines = read_file.readlines()\n",
    "    pred_pos = []\n",
    "    for line in lines:\n",
    "        pos = line.split(',')\n",
    "        x = float(pos[0])\n",
    "        y = float(pos[1])\n",
    "        pred_pos.append([x,y])\n",
    "    return pred_pos\n",
    "\n",
    "def cdf(error):\n",
    "    count = len(error)\n",
    "    cdf_y = [i/count for i in range(count)]\n",
    "    error_sorted = sorted(error)\n",
    "    plt.xlim(0,50)\n",
    "    plt.ylim(0,1)\n",
    "    plt.plot(error_sorted, cdf_y)\n",
    "    plt.show()\n",
    "    return cdf_y,error_sorted\n",
    "\n",
    "def error_analysis(pred_y,true_y):\n",
    "    error =np.sqrt((pred_y[:,0]-true_y[:,0])**2+(pred_y[:,1]-true_y[:,1])**2)\n",
    "    rms_error = rms(error)\n",
    "    print('rms_error:', rms_error)\n",
    "    mean_error = sum(error)/len(error)\n",
    "    print('mean_error:', mean_error)\n",
    "    print(\"generating cdf:\")\n",
    "    cdf_y,error_sorted = cdf(error)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   WAP001  WAP002  WAP003  WAP004  WAP005  WAP006  WAP007  WAP008  WAP009  \\\n",
      "0    -100    -100    -100    -100    -100    -100    -100    -100    -100   \n",
      "1    -100    -100    -100    -100    -100    -100    -100    -100    -100   \n",
      "\n",
      "   WAP010  ...  WAP511  WAP512  WAP513  WAP514  WAP515  WAP516  WAP517  \\\n",
      "0    -100  ...    -100    -100    -100    -100    -100    -100    -100   \n",
      "1    -100  ...    -100    -100    -100    -100    -100    -100    -100   \n",
      "\n",
      "   WAP518  WAP519  WAP520  \n",
      "0    -100    -100    -100  \n",
      "1    -100    -100    -100  \n",
      "\n",
      "[2 rows x 520 columns]\n"
     ]
    }
   ],
   "source": [
    "AP_features, building_ids_str, building_floors_str, labels = load_data('trainingData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   WAP001  WAP002  WAP003  WAP004  WAP005  WAP006  WAP007  WAP008  WAP009  \\\n",
      "0     100     100     100     100     100     100     100     100     100   \n",
      "1     100     100     100     100     100     100     100     100     100   \n",
      "\n",
      "   WAP010  ...  WAP520  LONGITUDE      LATITUDE  FLOOR  BUILDINGID  SPACEID  \\\n",
      "0     100  ...     100 -7541.2643  4.864921e+06      2           1      106   \n",
      "1     100  ...     100 -7536.6212  4.864934e+06      2           1      106   \n",
      "\n",
      "   RELATIVEPOSITION  USERID  PHONEID   TIMESTAMP  \n",
      "0                 2       2       23  1371713733  \n",
      "1                 2       2       23  1371713691  \n",
      "\n",
      "[2 rows x 529 columns]\n",
      "floor id (19937, 1)\n",
      "building id: (19937,)\n",
      "[-97 -94 -94 -94 -90 -90 -88 -88 -87 -86 -86 -84 -83 -83 -83 -80]\n",
      "[154  35 141 155  90  89 102 190 103 150 191 172 171   7 149 247]\n",
      "[[-150 -150 -150 ... -150 -150 -150]\n",
      " [-150 -150 -150 ... -150 -150 -150]\n",
      " [-150 -150 -150 ... -150 -150 -150]\n",
      " ...\n",
      " [-150 -150 -150 ... -150 -150 -150]\n",
      " [-150 -150 -150 ... -150 -150 -150]\n",
      " [-150 -150 -150 ... -150 -150 -150]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mlp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-de104bfed46b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0minput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtrain_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_rssi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_building_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mlp' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#import tensorflow_addons as tfa\n",
    "#from tensorflow_addons.layers import WeightNormalization\n",
    "#from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "path_train = \"trainingData.csv\"\n",
    "path_validation = \"validationData.csv\"\n",
    "train_df = pd.read_csv(path_train,header = 0)\n",
    "print(train_df.head(2))\n",
    "\n",
    "train_AP_strengths =train_df.loc[:,'WAP001':'WAP520']\n",
    "#train_AP_features= np.array(train_AP_strengths.replace([100], [-100]))\n",
    "building_ids_str = train_df[\"BUILDINGID\"].map(str) #convert all the building ids to strings\n",
    "building_floors_str = train_df[\"FLOOR\"].map(str) #convert all the building floors to strings\n",
    "#print(id_label)\n",
    "floor_enc = LabelEncoder()\n",
    "floor_enc.fit(building_floors_str)\n",
    "floor_id = floor_enc.transform(building_floors_str)\n",
    "floor_id = floor_id.reshape(-1,1)\n",
    "print(\"floor id\",(floor_id.shape))\n",
    "building_enc = LabelEncoder()\n",
    "building_enc.fit(building_ids_str)\n",
    "building_id = building_enc.transform(building_ids_str)\n",
    "train_building_id = building_id.reshape(-1,1)\n",
    "print(\"building id:\",(building_id.shape))\n",
    "\n",
    "train_AP_features = np.array(train_AP_strengths.replace([100],[-150]))\n",
    "##### 1) RSSI_FLOOR 2) SSID 3) BUILDING_ID\n",
    "train_id = np.argsort(train_AP_features)[:,504:520]\n",
    "train_rssi = np.sort(train_AP_features)[:,504:520]\n",
    "print(train_rssi[10])\n",
    "print(train_id[10])\n",
    "print(train_AP_features[train_id[10]])\n",
    "#train_rssi_floor = np.hstack((train_rssi,floor_id))\n",
    "#print(train_rssi_floor[0], train_rssi_floor.shape)\n",
    "#print(train_id[0],train_rssi[0],train_AP_features[0])\n",
    "\n",
    "input_data = [train_id, train_rssi, train_building_id]\n",
    "model = mlp(input_data)\n",
    "model.summary()\n",
    "\n",
    "train_df_LL = train_df.loc[:,'LONGITUDE':'LATITUDE']\n",
    "train_labels = np.asarray(train_df_LL)\n",
    "train_y,ranges,bias =  normalization(train_labels)\n",
    "print(bias,ranges)\n",
    "test_df = pd.read_csv(path_validation,header = 0)\n",
    "print(test_df.head(2))\n",
    "test_AP_strengths =test_df.loc[:,'WAP001':'WAP520']\n",
    "#test_AP_features = np.array(test_AP_strengths.replace([100], [-100]))\n",
    "test_building_ids_str = test_df[\"BUILDINGID\"].map(str) #convert all the building ids to strings\n",
    "test_building_floors_str = test_df[\"FLOOR\"].map(str) #convert all the building floors to strings\n",
    "#print(id_label)\n",
    "test_floor_enc = LabelEncoder()\n",
    "test_floor_enc.fit(building_floors_str)\n",
    "test_floor_id = test_floor_enc.transform(test_building_floors_str)\n",
    "test_floor_id = test_floor_id.reshape(-1,1)\n",
    "print(\"test floor id\",(test_floor_id.shape))\n",
    "test_building_enc = LabelEncoder()\n",
    "test_building_enc.fit(test_building_ids_str)\n",
    "test_building_id = test_building_enc.transform(test_building_ids_str)\n",
    "test_building_id = test_building_id.reshape(-1,1)\n",
    "print(\"test building id:\",(test_building_id.shape))\n",
    "test_AP_features = np.array(test_AP_strengths.replace([100],[-150]))\n",
    "test_id = np.argsort(test_AP_features)[:,504:520]\n",
    "test_rssi = np.sort(test_AP_features)[:,504:520]\n",
    "\n",
    "test_rssi_floor = np.hstack((test_rssi,test_floor_id))\n",
    "print(test_rssi_floor[0], test_rssi_floor.shape)\n",
    "\n",
    "test_df_LL = test_df.loc[:,'LONGITUDE':'LATITUDE']\n",
    "test_y = np.asarray(test_df_LL)\n",
    "#model.fit(input_data,train_y,nb_epoch=200,batch_size=128,callbacks=[\n",
    "       #ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1, min_delta=1e-4, mode='min')\n",
    "#,EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=5, mode='min', baseline=None, restore_best_weights=True)])\n",
    "#test_pred_y = model.predict([test_id, test_rssi, test_building_id])\n",
    "#test_pred_y = test_pred_y * ranges + bias \n",
    "#error_analysis(test_y, test_pred_y)\n",
    "\"\"\"one hot encode the dummy_labels.\n",
    "this is done because dummy_labels is a dataframe with the labels (BUILDINGID+FLOOR) \n",
    "as the column names\n",
    "\"\"\"\n",
    "#train_X,train_y, val_X, val_y = train_val_split(train_AP_features,train_labels)\n",
    "\n",
    "#Turn the given validation set into a testing set\n",
    "#test_df = pd.read_csv(path_validation,header = 0)\n",
    "#test_AP_features = (np.asarray(test_df.loc[:,'WAP001':'WAP520']))/200+0.5\n",
    "#test_labels = np.asarray(test_df[\"BUILDINGID\"].map(str) + test_df[\"FLOOR\"].map(str))\n",
    "#test_labels = np.asarray(pd.get_dummies(test_labels))\n",
    "#input_size = 520"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn(input_data):\n",
    "    print(\"using CNN\")\n",
    "    wapid_dim = input_data[0].shape[1]\n",
    "    wapid_input_layer = L.Input(shape=(wapid_dim,))\n",
    "    wap_emb = L.Embedding(520,40)(wapid_input_layer)\n",
    "    wap_emb = L.BatchNormalization()(wap_emb)\n",
    "    wap_emb = L.Flatten()(wap_emb)\n",
    "    \n",
    "    rssi_f_dim = input_data[1].shape[1]\n",
    "    rssi_f_input_layer = L.Input(shape=(rssi_f_dim,))\n",
    "    rssi_f = L.BatchNormalization()(rssi_f_input_layer)\n",
    "    rssi_f_feature = L.Dense(16*40, activation='relu')(rssi_f)\n",
    "    \n",
    "    \n",
    "    input_site_layer = L.Input(shape=(1,))\n",
    "    print(\"input_site_layer\", input_site_layer.shape)\n",
    "    site_emb = L.Embedding(13, 1)(input_site_layer)\n",
    "    print(\"site_emb1\", site_emb.shape)\n",
    "    site_emb = L.Flatten()(site_emb)\n",
    "    print(\"site_emb2\", site_emb.shape)\n",
    "    site_emb = L.BatchNormalization()(site_emb)\n",
    "    print(\"site_emb3\", site_emb.shape)\n",
    "    x = L.Concatenate(axis=1)([wap_emb, rssi_f_feature])\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.Dropout(0.2)(x)\n",
    "    x = L.Dense(256, activation='relu')(x)\n",
    "    x = L.Dropout(0.1)(x)\n",
    "    x = L.Dense(128, activation='relu')(x)\n",
    "    print(\"before\",x.shape)\n",
    "    x = L.Reshape((128, 1))(x)\n",
    "    print(\"before2\",x.shape)\n",
    "    x = L.BatchNormalization()(x)   # input 128\n",
    "    x = L.Conv1D(32, 3, strides=1, dilation_rate=1, activation='relu')(x)   # input 128, output 126\n",
    "    print(\"CNN1\",x.shape)\n",
    "    y = x\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.Conv1D(64, 5, strides=2, dilation_rate=1, activation='relu')(x)   # input 126, output (126-5+0)/2+1 = 61\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.Conv1D(128, 7, strides=2, dilation_rate=1, activation='relu')(x)  # input 61, output (61-7+0)/2+1 = 28\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.Conv1D(64, 9, strides=1, dilation_rate=1, activation='relu')(x)  # input 23, output (28-9+0)/1+1 = 20\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.Conv1D(32, 5, strides=1, dilation_rate=1, activation='relu')(x)   # input 20, output (20-5+0)/1+1 = 16\n",
    "    print(\"CNN_5 \", x.shape)\n",
    "    x = L.Concatenate(axis=1)([x, y])\n",
    "    x = L.BatchNormalization()(x)\n",
    "    print(\"CNN_res \", x.shape)\n",
    "    x = L.Conv1D(1, 1, strides=1, dilation_rate=1, activation='relu')(x)    # gloabl average pooling\n",
    "    x = L.BatchNormalization()(x)  \n",
    "    print(\"after cnn\", x.shape)\n",
    "    x = L.Flatten()(x)\n",
    "    print(\"after flatten\", x.shape)\n",
    "    x = L.Dense(64, activation='relu')(x)\n",
    "    x = L.Concatenate(axis=1)([x,site_emb])\n",
    "    x = L.Dense(32, activation='relu')(x)\n",
    "    output_layer_1 = L.Dense(2, name='xy')(x)\n",
    "    model = M.Model([wapid_input_layer, rssi_f_input_layer, input_site_layer], [output_layer_1])\n",
    "    model.compile(optimizer=tf.optimizers.Adam(lr=0.001), loss='mse', metrics=['mse'])\n",
    "    return model\n",
    "\n",
    "def cnn_lstm(input_data):\n",
    "    wapid_dim = input_data[0].shape[1]\n",
    "    wapid_input_layer = L.Input(shape=(wapid_dim,))\n",
    "    wap_emb = L.Embedding(520,40)(wapid_input_layer)\n",
    "    wap_emb = L.BatchNormalization()(wap_emb)\n",
    "    wap_emb = L.Flatten()(wap_emb)\n",
    "    \n",
    "    rssi_f_dim = input_data[1].shape[1]\n",
    "    rssi_f_input_layer = L.Input(shape=(rssi_f_dim,))\n",
    "    rssi_f = L.BatchNormalization()(rssi_f_input_layer)\n",
    "    rssi_f_feature = L.Dense(16*40, activation='relu')(rssi_f)\n",
    "    \n",
    "    \n",
    "    input_site_layer = L.Input(shape=(1,))\n",
    "    site_emb = L.Embedding(13, 1)(input_site_layer)\n",
    "    site_emb = L.Flatten()(site_emb)\n",
    "    site_emb = L.BatchNormalization()(site_emb)\n",
    "    x = L.Concatenate(axis=1)([wap_emb, rssi_f_feature])\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.Dropout(0.2)(x)\n",
    "    x = L.Dense(256, activation='relu')(x)\n",
    "    x = L.Dropout(0.1)(x)\n",
    "    x = L.Dense(128, activation='relu')(x)\n",
    "    #x = L.Dropout(0.2)(x)\n",
    "    x = L.Reshape((128, 1))(x)\n",
    "    # x = L.Reshape((-1, 1))(x)\n",
    "    x = L.BatchNormalization()(x)\n",
    "    \n",
    "    x = L.Conv1D(32, 3, strides=1, dilation_rate=1, activation='relu')(x)   # input 128, output 126\n",
    "    y = x\n",
    "    print(\"CNN1\",x.shape)\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.Conv1D(64, 5, strides=2, dilation_rate=1, activation='relu')(x)   # input 126, output (126-5+0)/2+1 = 61\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.Conv1D(128, 7, strides=2, dilation_rate=1, activation='relu')(x)  # input 61, output (61-7+0)/2+1 = 28\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.Conv1D(64, 9, strides=1, dilation_rate=1, activation='relu')(x)  # input 23, output (28-9+0)/1+1 = 20\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.Conv1D(32, 5, strides=1, dilation_rate=1, activation='relu')(x)   # input 20, output (20-5+0)/1+1 = 16\n",
    "    x = L.BatchNormalization()(x)\n",
    "    # x = L.Concatenate(axis=1)([x, y])\n",
    "    # x = L.Dense(64, activation='relu')(x)\n",
    "    x = L.Conv1D(1, 1, strides=1, dilation_rate=1, activation='relu')(x)    # gloabl average pooling\n",
    "    print(\"after conv1D\", x.shape)\n",
    "    x = L.BatchNormalization()(x) \n",
    "    x = L.LSTM(128, dropout=0, return_sequences=True, activation='sigmoid')(x)\n",
    "    x = L.LSTM(16, dropout=0, return_sequences=False, activation='sigmoid')(x)\n",
    "    print(\"after LSTM \", x.shape)\n",
    "    x = L.Concatenate(axis=1)([x,site_emb]) \n",
    "    x = L.Dense(64, activation='relu')(x)\n",
    "    x = L.Dense(16, activation='relu')(x)\n",
    "    #x = L.Dropout(0.1)(x)\n",
    "    output_layer_1 = L.Dense(2, name='xy', activation='sigmoid')(x)\n",
    "    model = M.Model([wapid_input_layer, rssi_f_input_layer, input_site_layer], [output_layer_1])\n",
    "    model.compile(optimizer=tf.optimizers.Adam(lr=0.001), loss='mse', metrics=['mse'])\n",
    "    return model\n",
    "def mlp(input_data):\n",
    "    wapid_dim = input_data[0].shape[1]\n",
    "    wapid_input_layer = L.Input(shape=(wapid_dim,))\n",
    "    wap_emb = L.Embedding(520,40)(wapid_input_layer)\n",
    "    wap_emb = L.BatchNormalization()(wap_emb)\n",
    "    wap_emb = L.Flatten()(wap_emb)\n",
    "    \n",
    "    rssi_f_dim = input_data[1].shape[1]\n",
    "    rssi_f_input_layer = L.Input(shape=(rssi_f_dim,))\n",
    "    rssi_f = L.BatchNormalization()(rssi_f_input_layer)\n",
    "    rssi_f_feature = L.Dense(16*40, activation='relu')(rssi_f)\n",
    "    \n",
    "    \n",
    "    input_site_layer = L.Input(shape=(1,))\n",
    "    site_emb = L.Embedding(13, 1)(input_site_layer)\n",
    "    site_emb = L.Flatten()(site_emb)\n",
    "    site_emb = L.BatchNormalization()(site_emb)\n",
    "    x = L.Concatenate(axis=1)([wap_emb, rssi_f_feature])\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.Dropout(0.1)(x)\n",
    "    x = L.Dense(256, activation='relu')(x)\n",
    "    x = L.Dropout(0.2)(x)\n",
    "    #x = L.Reshape((-1, 1))(x)\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.Dense(128,activation='relu')(x)\n",
    "    x = L.Dropout(0.1)(x)\n",
    "    x = L.Dense(64, activation='relu')(x)\n",
    "    x = L.Concatenate(axis=1)([x,site_emb])\n",
    "    x = L.Dense(16, activation='relu')(x)\n",
    "    #x = L.Dropout(0.1)(x)\n",
    "    output_layer_1 = L.Dense(2, name='xy')(x)\n",
    "    model = M.Model([wapid_input_layer, rssi_f_input_layer, input_site_layer], [output_layer_1])\n",
    "    model.compile(optimizer=tf.optimizers.Adam(lr=0.001), loss='mse', metrics=['mse'])\n",
    "    model.summary()\n",
    "    return model\n",
    "def lstm(input_data):\n",
    "    wapid_dim = input_data[0].shape[1]\n",
    "    wapid_input_layer = L.Input(shape=(wapid_dim,))\n",
    "    wap_emb = L.Embedding(520,40)(wapid_input_layer)\n",
    "    wap_emb = L.BatchNormalization()(wap_emb)\n",
    "    wap_emb = L.Flatten()(wap_emb)\n",
    "    \n",
    "    rssi_f_dim = input_data[1].shape[1]\n",
    "    rssi_f_input_layer = L.Input(shape=(rssi_f_dim,))\n",
    "    rssi_f = L.BatchNormalization()(rssi_f_input_layer)\n",
    "    rssi_f_feature = L.Dense(16*40, activation='relu')(rssi_f)\n",
    "    \n",
    "    \n",
    "    input_site_layer = L.Input(shape=(1,))\n",
    "    site_emb = L.Embedding(13, 1)(input_site_layer)\n",
    "    site_emb = L.Flatten()(site_emb)\n",
    "    site_emb = L.BatchNormalization()(site_emb)\n",
    "    x = L.Concatenate(axis=1)([wap_emb, rssi_f_feature])\n",
    "    x = L.BatchNormalization()(x)\n",
    "    #x = L.Dropout(0.2)(x)\n",
    "    #x = L.Dense(256, activation='relu')(x)\n",
    "    x = L.Dropout(0.1)(x)\n",
    "    x = L.Dense(128, activation='relu')(x)\n",
    "    #x = L.Dropout(0.2)(x)\n",
    "    x = L.Reshape((-1, 1))(x)\n",
    "    print(x.shape)\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.LSTM(128, dropout=0.1, recurrent_dropout=0, return_sequences=True, activation='sigmoid')(x)\n",
    "    x = L.LSTM(64, dropout=0.1, return_sequences=False, activation='sigmoid')(x)\n",
    "    #x = L.Dense(128,activation='relu')(x)\n",
    "    #x = L.Dropout(0.2)(x)\n",
    "    #x = L.Reshape((-1, 1))(x)\n",
    "    x = L.Dense(64, activation='relu')(x)\n",
    "    #x = L.LSTM(16, dropout=0, return_sequences=False, activation='relu')(x)\n",
    "    x = L.Concatenate(axis=1)([x,site_emb])\n",
    "    x = L.Dense(16, activation='relu')(x)\n",
    "    #x = L.Dropout(0.1)(x)\n",
    "    output_layer_1 = L.Dense(2, name='xy')(x)\n",
    "    model = M.Model([wapid_input_layer, rssi_f_input_layer, input_site_layer], [output_layer_1])\n",
    "    model.compile(optimizer=tf.optimizers.Adam(lr=0.001), loss='mse', metrics=['mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mlp_files():\n",
    "    files = ['mlp_dropout_layer_result_0.3.txt','mlp_dropout_layer_result_0.5.txt','mlp_dropout_layer_result_0.7.txt',\n",
    "             'mlp_dropout_layer_result_0.9.txt','mlp_dropout_layer_result_1.0.txt']\n",
    "    import pickle\n",
    "    for fileName in files:\n",
    "        file = open(fileName, 'rb')\n",
    "        test_pred_y = pickle.load(file)\n",
    "        error_analysis(test_y, test_pred_y)\n",
    "load_mlp_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split(xs, y,ratio):\n",
    "    new_xs = []\n",
    "    new_y = []\n",
    "    train_val_split = np.random.rand(len(y))\n",
    "    train_val_split = train_val_split < ratio #should contain ~70% percent true\n",
    "    for x in xs:\n",
    "        x = x[train_val_split]\n",
    "        new_xs.append(x)\n",
    "    y = y[train_val_split]\n",
    "    new_y.append(y)\n",
    "    return new_xs, new_y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_val_split(xs, y,ratio):\n",
    "    new_xs = []\n",
    "    new_y = []\n",
    "    train_val_split = np.random.rand(len(y))\n",
    "    train_val_split = train_val_split < ratio #should contain ~70% percent true\n",
    "    for x in xs:\n",
    "        x = x[train_val_split]\n",
    "        new_xs.append(x)\n",
    "    y = y[train_val_split]\n",
    "    new_y.append(y)\n",
    "    return new_xs, new_y\n",
    "\n",
    "import pickle\n",
    "for i in [1]:\n",
    "    ratio = i * 0.1\n",
    "    part_train_x, part_train_y = train_val_split(input_data, train_y, ratio) \n",
    "    print(\"ratio: \"+ str(i)) \n",
    "    model = lstm(part_train_x)\n",
    "    #model.compile(optimizer=tf.optimizers.Adam(lr=0.001), loss='mse', metrics=['mse'])\n",
    "    model.fit(part_train_x,part_train_y,nb_epoch=100,batch_size=128,verbose = 1)\n",
    "    test_pred_y = model.predict([test_id, test_rssi, test_building_id])\n",
    "    test_pred_y = test_pred_y * ranges + bias \n",
    "    error_analysis(test_y, test_pred_y)\n",
    "    fileName = 'lstm_2_layer_result_' + str(ratio)+ '.txt'\n",
    "    print(\"writing to file name: \", fileName)\n",
    "    file = open(fileName,'wb')\n",
    "    pickle.dump(test_pred_y,file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-97 -94 -94 -94 -90 -90 -88 -88 -87 -86 -86 -84 -83 -83 -83 -80]\n",
      "[154  35 141 155  90  89 102 190 103 150 191 172 171   7 149 247]\n",
      "[[-150 -150 -150 ... -150 -150 -150]\n",
      " [-150 -150 -150 ... -150 -150 -150]\n",
      " [-150 -150 -150 ... -150 -150 -150]\n",
      " ...\n",
      " [-150 -150 -150 ... -150 -150 -150]\n",
      " [-150 -150 -150 ... -150 -150 -150]\n",
      " [-150 -150 -150 ... -150 -150 -150]]\n",
      "[  -7691.3384     4864745.74501597] [390.51940991 270.94278403]\n",
      "   WAP001  WAP002  WAP003  WAP004  WAP005  WAP006  WAP007  WAP008  WAP009  \\\n",
      "0     100     100     100     100     100     100     100     100     100   \n",
      "1     100     100     100     100     100     100     100     100     100   \n",
      "\n",
      "   WAP010  ...  WAP520    LONGITUDE      LATITUDE  FLOOR  BUILDINGID  SPACEID  \\\n",
      "0     100  ...     100 -7515.916799  4.864890e+06      1           1        0   \n",
      "1     100  ...     100 -7383.867221  4.864840e+06      4           2        0   \n",
      "\n",
      "   RELATIVEPOSITION  USERID  PHONEID   TIMESTAMP  \n",
      "0                 0       0        0  1380872703  \n",
      "1                 0       0       13  1381155054  \n",
      "\n",
      "[2 rows x 529 columns]\n",
      "test floor id (1111, 1)\n",
      "test building id: (1111, 1)\n",
      "[-150 -150 -150 -150 -150 -150 -150 -150 -150 -150 -150 -150 -150 -150\n",
      " -150  -91    1] (1111, 17)\n",
      "CNN1 (None, 126, 32)\n",
      "after conv1D (None, 16, 1)\n",
      "after LSTM  (None, 16)\n",
      "WARNING:tensorflow:The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "Train on 19937 samples\n",
      "Epoch 1/100\n",
      "19937/19937 [==============================] - 17s 851us/sample - loss: 0.0225 - mse: 0.0225\n",
      "Epoch 2/100\n",
      "19937/19937 [==============================] - 15s 767us/sample - loss: 0.0058 - mse: 0.0058\n",
      "Epoch 3/100\n",
      "19937/19937 [==============================] - 16s 780us/sample - loss: 0.0050 - mse: 0.0050\n",
      "Epoch 4/100\n",
      "19937/19937 [==============================] - 15s 775us/sample - loss: 0.0043 - mse: 0.0043\n",
      "Epoch 5/100\n",
      "19937/19937 [==============================] - 15s 735us/sample - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 6/100\n",
      "19937/19937 [==============================] - 15s 740us/sample - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 7/100\n",
      "19937/19937 [==============================] - 15s 744us/sample - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 8/100\n",
      "19937/19937 [==============================] - 15s 739us/sample - loss: 0.0012 - mse: 0.0012\n",
      "Epoch 9/100\n",
      "19937/19937 [==============================] - 15s 758us/sample - loss: 9.6180e-04 - mse: 9.6180e-04\n",
      "Epoch 10/100\n",
      "19937/19937 [==============================] - 15s 759us/sample - loss: 0.0010 - mse: 0.0010\n",
      "Epoch 11/100\n",
      "19937/19937 [==============================] - 15s 746us/sample - loss: 0.0010 - mse: 0.0010\n",
      "Epoch 12/100\n",
      "19937/19937 [==============================] - 15s 743us/sample - loss: 0.0011 - mse: 0.0011\n",
      "Epoch 13/100\n",
      "19937/19937 [==============================] - 15s 739us/sample - loss: 9.0009e-04 - mse: 9.0009e-04\n",
      "Epoch 14/100\n",
      "19937/19937 [==============================] - 15s 745us/sample - loss: 9.6824e-04 - mse: 9.6823e-04\n",
      "Epoch 15/100\n",
      "19937/19937 [==============================] - 15s 742us/sample - loss: 0.0010 - mse: 0.0010\n",
      "Epoch 16/100\n",
      "19937/19937 [==============================] - 15s 754us/sample - loss: 9.0612e-04 - mse: 9.0612e-04\n",
      "Epoch 17/100\n",
      "19937/19937 [==============================] - 15s 774us/sample - loss: 6.7062e-04 - mse: 6.7062e-04 - loss: 6.7724e-04 - mse: 6.772\n",
      "Epoch 18/100\n",
      "19937/19937 [==============================] - 15s 768us/sample - loss: 6.4396e-04 - mse: 6.4396e-04\n",
      "Epoch 19/100\n",
      "19937/19937 [==============================] - 15s 767us/sample - loss: 7.3228e-04 - mse: 7.3228e-04\n",
      "Epoch 20/100\n",
      "19937/19937 [==============================] - 15s 766us/sample - loss: 7.3722e-04 - mse: 7.3722e-04\n",
      "Epoch 21/100\n",
      "19937/19937 [==============================] - 15s 769us/sample - loss: 6.6451e-04 - mse: 6.6451e-04\n",
      "Epoch 22/100\n",
      "19937/19937 [==============================] - 15s 766us/sample - loss: 6.0576e-04 - mse: 6.0576e-04\n",
      "Epoch 23/100\n",
      "19937/19937 [==============================] - 15s 773us/sample - loss: 6.3361e-04 - mse: 6.3361e-04\n",
      "Epoch 24/100\n",
      "19937/19937 [==============================] - 16s 786us/sample - loss: 6.0673e-04 - mse: 6.0673e-04\n",
      "Epoch 25/100\n",
      "19937/19937 [==============================] - 16s 801us/sample - loss: 5.6405e-04 - mse: 5.6405e-04\n",
      "Epoch 26/100\n",
      "19937/19937 [==============================] - 16s 783us/sample - loss: 4.1749e-04 - mse: 4.1749e-04\n",
      "Epoch 27/100\n",
      "19937/19937 [==============================] - 16s 781us/sample - loss: 6.1076e-04 - mse: 6.1076e-04\n",
      "Epoch 28/100\n",
      "19937/19937 [==============================] - 16s 782us/sample - loss: 4.9614e-04 - mse: 4.9614e-04\n",
      "Epoch 29/100\n",
      "19937/19937 [==============================] - 16s 785us/sample - loss: 4.9227e-04 - mse: 4.9227e-04\n",
      "Epoch 30/100\n",
      "19937/19937 [==============================] - 16s 788us/sample - loss: 3.8978e-04 - mse: 3.8978e-04\n",
      "Epoch 31/100\n",
      "19937/19937 [==============================] - 16s 786us/sample - loss: 3.7916e-04 - mse: 3.7916e-04\n",
      "Epoch 32/100\n",
      "19937/19937 [==============================] - 16s 785us/sample - loss: 4.2980e-04 - mse: 4.2980e-04\n",
      "Epoch 33/100\n",
      "19937/19937 [==============================] - 16s 786us/sample - loss: 3.9785e-04 - mse: 3.9785e-04\n",
      "Epoch 34/100\n",
      "19937/19937 [==============================] - 16s 789us/sample - loss: 3.4098e-04 - mse: 3.4098e-04\n",
      "Epoch 35/100\n",
      "19937/19937 [==============================] - 16s 787us/sample - loss: 3.5365e-04 - mse: 3.5365e-04\n",
      "Epoch 36/100\n",
      "19937/19937 [==============================] - 16s 787us/sample - loss: 4.2015e-04 - mse: 4.2015e-04\n",
      "Epoch 37/100\n",
      "19937/19937 [==============================] - 16s 787us/sample - loss: 3.3556e-04 - mse: 3.3556e-04\n",
      "Epoch 38/100\n",
      "19937/19937 [==============================] - 16s 787us/sample - loss: 3.2608e-04 - mse: 3.2608e-04\n",
      "Epoch 39/100\n",
      "19937/19937 [==============================] - 16s 784us/sample - loss: 3.5439e-04 - mse: 3.5439e-04\n",
      "Epoch 40/100\n",
      "19937/19937 [==============================] - 16s 782us/sample - loss: 2.8920e-04 - mse: 2.8920e-04\n",
      "Epoch 41/100\n",
      "19937/19937 [==============================] - 16s 781us/sample - loss: 2.9316e-04 - mse: 2.9316e-04\n",
      "Epoch 42/100\n",
      "19937/19937 [==============================] - 16s 784us/sample - loss: 3.1592e-04 - mse: 3.1592e-04\n",
      "Epoch 43/100\n",
      "19937/19937 [==============================] - 16s 786us/sample - loss: 2.7691e-04 - mse: 2.7691e-04\n",
      "Epoch 44/100\n",
      "19937/19937 [==============================] - 16s 783us/sample - loss: 2.3891e-04 - mse: 2.3891e-04\n",
      "Epoch 45/100\n",
      "19937/19937 [==============================] - 16s 785us/sample - loss: 2.4745e-04 - mse: 2.4745e-04\n",
      "Epoch 46/100\n",
      "19937/19937 [==============================] - 16s 782us/sample - loss: 2.6702e-04 - mse: 2.6702e-04\n",
      "Epoch 47/100\n",
      "19937/19937 [==============================] - 16s 781us/sample - loss: 2.3515e-04 - mse: 2.3515e-04\n",
      "Epoch 48/100\n",
      "19937/19937 [==============================] - 16s 784us/sample - loss: 2.2956e-04 - mse: 2.2956e-04\n",
      "Epoch 49/100\n",
      "19937/19937 [==============================] - 16s 828us/sample - loss: 2.2684e-04 - mse: 2.2684e-04\n",
      "Epoch 50/100\n",
      "19937/19937 [==============================] - 16s 788us/sample - loss: 2.5450e-04 - mse: 2.5450e-04\n",
      "Epoch 51/100\n",
      "19937/19937 [==============================] - 16s 803us/sample - loss: 2.1309e-04 - mse: 2.1309e-04\n",
      "Epoch 52/100\n",
      "19937/19937 [==============================] - 16s 809us/sample - loss: 2.1381e-04 - mse: 2.1381e-04\n",
      "Epoch 53/100\n",
      "19937/19937 [==============================] - 17s 828us/sample - loss: 2.0148e-04 - mse: 2.0148e-04\n",
      "Epoch 54/100\n",
      "19937/19937 [==============================] - 15s 773us/sample - loss: 1.8714e-04 - mse: 1.8714e-04\n",
      "Epoch 55/100\n",
      "19937/19937 [==============================] - 15s 773us/sample - loss: 1.8566e-04 - mse: 1.8566e-04\n",
      "Epoch 56/100\n",
      "19937/19937 [==============================] - 15s 774us/sample - loss: 1.8201e-04 - mse: 1.8201e-04\n",
      "Epoch 57/100\n",
      "19937/19937 [==============================] - 15s 770us/sample - loss: 1.8078e-04 - mse: 1.8078e-04\n",
      "Epoch 58/100\n",
      "19937/19937 [==============================] - 15s 771us/sample - loss: 1.7858e-04 - mse: 1.7858e-04\n",
      "Epoch 59/100\n",
      "19937/19937 [==============================] - 15s 773us/sample - loss: 1.8214e-04 - mse: 1.8214e-04\n",
      "Epoch 60/100\n",
      "19937/19937 [==============================] - 15s 774us/sample - loss: 2.0177e-04 - mse: 2.0177e-04\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19937/19937 [==============================] - 15s 765us/sample - loss: 1.8474e-04 - mse: 1.8474e-04\n",
      "Epoch 62/100\n",
      "19937/19937 [==============================] - 15s 764us/sample - loss: 1.7193e-04 - mse: 1.7193e-04\n",
      "Epoch 63/100\n",
      "19937/19937 [==============================] - 15s 765us/sample - loss: 1.6100e-04 - mse: 1.6100e-04\n",
      "Epoch 64/100\n",
      "19937/19937 [==============================] - 15s 765us/sample - loss: 1.6544e-04 - mse: 1.6544e-04\n",
      "Epoch 65/100\n",
      "19937/19937 [==============================] - 15s 761us/sample - loss: 1.7441e-04 - mse: 1.7441e-04\n",
      "Epoch 66/100\n",
      "19937/19937 [==============================] - 15s 764us/sample - loss: 1.7682e-04 - mse: 1.7682e-04\n",
      "Epoch 67/100\n",
      "19937/19937 [==============================] - 15s 764us/sample - loss: 1.6747e-04 - mse: 1.6747e-04\n",
      "Epoch 68/100\n",
      "19937/19937 [==============================] - 16s 805us/sample - loss: 1.5614e-04 - mse: 1.5614e-04\n",
      "Epoch 69/100\n",
      "19937/19937 [==============================] - 16s 789us/sample - loss: 1.5584e-04 - mse: 1.5584e-04\n",
      "Epoch 70/100\n",
      "19937/19937 [==============================] - 16s 802us/sample - loss: 1.5442e-04 - mse: 1.5442e-04\n",
      "Epoch 71/100\n",
      "19937/19937 [==============================] - 16s 812us/sample - loss: 1.5724e-04 - mse: 1.5724e-04\n",
      "Epoch 72/100\n",
      "19937/19937 [==============================] - 17s 853us/sample - loss: 1.6250e-04 - mse: 1.6250e-04\n",
      "Epoch 73/100\n",
      "19937/19937 [==============================] - 16s 806us/sample - loss: 1.5488e-04 - mse: 1.5488e-04\n",
      "Epoch 74/100\n",
      "19937/19937 [==============================] - 16s 790us/sample - loss: 1.5253e-04 - mse: 1.5253e-04\n",
      "Epoch 75/100\n",
      "19937/19937 [==============================] - 16s 793us/sample - loss: 1.4671e-04 - mse: 1.4671e-04\n",
      "Epoch 76/100\n",
      "19937/19937 [==============================] - 16s 795us/sample - loss: 1.5643e-04 - mse: 1.5643e-04\n",
      "Epoch 77/100\n",
      "19937/19937 [==============================] - 16s 790us/sample - loss: 1.4926e-04 - mse: 1.4926e-04\n",
      "Epoch 78/100\n",
      "19937/19937 [==============================] - 16s 798us/sample - loss: 1.4780e-04 - mse: 1.4780e-04\n",
      "Epoch 79/100\n",
      "19937/19937 [==============================] - 16s 792us/sample - loss: 1.4529e-04 - mse: 1.4529e-04\n",
      "Epoch 80/100\n",
      "19937/19937 [==============================] - 16s 800us/sample - loss: 1.7811e-04 - mse: 1.7811e-04\n",
      "Epoch 81/100\n",
      "19937/19937 [==============================] - 16s 794us/sample - loss: 1.5381e-04 - mse: 1.5381e-04\n",
      "Epoch 82/100\n",
      "19937/19937 [==============================] - 16s 796us/sample - loss: 1.4890e-04 - mse: 1.4890e-04\n",
      "Epoch 83/100\n",
      "19937/19937 [==============================] - 16s 789us/sample - loss: 1.4611e-04 - mse: 1.4611e-04\n",
      "Epoch 84/100\n",
      "19937/19937 [==============================] - 16s 791us/sample - loss: 1.3941e-04 - mse: 1.3941e-04\n",
      "Epoch 85/100\n",
      "19937/19937 [==============================] - 16s 795us/sample - loss: 1.3808e-04 - mse: 1.3808e-04\n",
      "Epoch 86/100\n",
      "19937/19937 [==============================] - 16s 787us/sample - loss: 1.3030e-04 - mse: 1.3030e-04\n",
      "Epoch 87/100\n",
      "19937/19937 [==============================] - 16s 790us/sample - loss: 1.4340e-04 - mse: 1.4340e-04\n",
      "Epoch 88/100\n",
      "19937/19937 [==============================] - 16s 793us/sample - loss: 1.5469e-04 - mse: 1.5469e-04\n",
      "Epoch 89/100\n",
      "19937/19937 [==============================] - 16s 793us/sample - loss: 1.4452e-04 - mse: 1.4452e-04\n",
      "Epoch 90/100\n",
      "19937/19937 [==============================] - 16s 796us/sample - loss: 1.3619e-04 - mse: 1.3619e-04\n",
      "Epoch 91/100\n",
      "19937/19937 [==============================] - 16s 802us/sample - loss: 1.3042e-04 - mse: 1.3042e-04\n",
      "Epoch 92/100\n",
      "19937/19937 [==============================] - 16s 789us/sample - loss: 1.3677e-04 - mse: 1.3677e-04\n",
      "Epoch 93/100\n",
      "19937/19937 [==============================] - 16s 788us/sample - loss: 1.4281e-04 - mse: 1.4281e-04\n",
      "Epoch 94/100\n",
      "19937/19937 [==============================] - 16s 790us/sample - loss: 1.3374e-04 - mse: 1.3374e-04\n",
      "Epoch 95/100\n",
      "19937/19937 [==============================] - 16s 794us/sample - loss: 1.3226e-04 - mse: 1.3226e-04\n",
      "Epoch 96/100\n",
      "19937/19937 [==============================] - 16s 802us/sample - loss: 1.3333e-04 - mse: 1.3333e-04\n",
      "Epoch 97/100\n",
      "19937/19937 [==============================] - 16s 793us/sample - loss: 1.2540e-04 - mse: 1.2540e-04\n",
      "Epoch 98/100\n",
      "19937/19937 [==============================] - 16s 800us/sample - loss: 1.2682e-04 - mse: 1.2682e-04\n",
      "Epoch 99/100\n",
      "19937/19937 [==============================] - 16s 813us/sample - loss: 1.3503e-04 - mse: 1.3503e-04\n",
      "Epoch 100/100\n",
      "19937/19937 [==============================] - 16s 797us/sample - loss: 1.2517e-04 - mse: 1.2517e-04\n",
      "rms_error: 12.01016394142531\n",
      "mean_error: 8.35409574526561\n",
      "generating cdf:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAfm0lEQVR4nO3deXhV13nv8e+rGQkkMQgMCDGZ0WAwKNiJHZt4xITaGWzXrn3T1q5J0qRNbtP2cdLWzU3T3Ka9TdPc+tohQ+M4g+tmKq5JPAU7HgJGYIOZETMSIAmheTrDe/84B5AxIAFH2mf4fR7rOXtYOufVts/P+1l77bXN3RERkfSVFXQBIiIysBT0IiJpTkEvIpLmFPQiImlOQS8ikuYU9CIiaa7PoDez75pZnZltPst+M7NvmFm1mW0yswWJL1NERC5Uf87ovwcsOcf+W4Fp8Z/lwKMXX5aIiCRKn0Hv7r8BGs/R5Hbg+x6zBig1s7GJKlBERC5OTgLeYzxwsNf6ofi2w6c3NLPlxM76KSoqWjhz5swEfLyISOZYv359g7uXnc/vJCLo+83dVwArACorK72qqmowP15E5JzcnUjU6YlECUedSMRjr1En4ifWo0Sip7aHo044EmXt3kYa23toaOumKxShKxSNvYajdIciRKKOA1F3iP1D1J3YqhONxmp4xzaH2Cw1J5Yd1t+y/3z/rkQEfQ0wodd6eXybiMg59YSjtHWHCUeihOKBGYpECUWccMQJRaOEI37aficUiRKOnmp3YrknHKWlK0RzZ4jWrjA94Qg94VP7uiNRQuEoPfHP6QnHfyKnXi92+q8JI4YwJDebIbnZ5OdmUzIkl/xh+eRkGVlmEPuHLDOs1zIW3waYndoPRpYRb2u8dQE1JSLoVwKfNrMngSuBZnd/V7eNiKQOd6exvefU2Ww0dpYZiZ/xRnu9RqPn3t4TjtLSGToZwC2dYVq6Quypb+PtmmZCkcROrJiTZZQMyaV4SC75OVnk5WSRm51FXnYWJXm55GVnkZdj8df4vpysd6zHfoycLCM7y8jOyjq5nJMdf+21PSvLGJKbTeXE4WRlWUL/ntN9+QJ+p8+gN7MfA4uBUWZ2CPhbIBfA3R8DVgFLgWqgA/jDC6hDRAZAfWs37d1huuNnrt3hCN3x1/rWbmqaumju6KGpMxbCTR0hWjpDHGnpoqMnMiA1FeXFznLLigu4/5rJjC0uIOdksGaRk23kZscCNDcni9yT286wPx7KOdlGblYWuTmxwDUb2LBNNX0Gvbvf08d+Bz6VsIpE0lhjew9NHT0nux9CvboieiKxborOUITmzhDNHT20dofpDkVPhnNsORbWoXj7E10ap3d19ESiNLT1nLMeMyguyKVkSC6lhbHX8uFDuG5GGRUjCsnLySLbYmesWWZkZxF/tXNutxPLWZCbnXXyM4YV5JCTrfs0B9ugXowVyRSRqNPSGeJwcxfr9zeypbaFLbUtbK5tPq8+4LzsLPJzs8jPyaYgN4v8nNhyrIvByMvJojA7i9x4l0LOyeXY/vLhhYwtKSA/J/tkN8aJ15FF+YwrLVDwZgAFvch5cHe6QlEa2rpZs+cYu+raaGjrpqkjxPGOnpOvzZ2hdwT68MJcLhtXwh8vnsr0McPe0Q+cl511Mphzs7MoyM2ieEjsDDg/Jzu4P1bShoJepJdI1OmOj9SI9WnHfjp7Ijy9qZafbaihoa37ZPu87CzKhuUzvCiX4YV5lA8vZHhhLqVDciktzGPk0DwWVAynfPgQ9RtLYBT0khEiUed4Rw/H23s41n7qtamjh8b2EAca29l0qJm61u6zvocZXDutjCunjGB4YR4TRxRy5ZSRZA/wKAuRi6Wgl7QTiTrH2rrZVdfGj944wOaaZg4d7yQSPXPn+ND8HMaWFHDNpaOoGFl4xv7s/JwsZo8toWJk4SD/NSIXT0EvKe9gYwc/XBsL9IPHO6ht6jw5NntYQQ7XTitj2eVjGT2sgOFFeYwsymN4YR4jivIYXqR+cEl/CnpJGc2dIV6rbmDHkVbermmmqSPW/bL/WAcA40uHcEVFKUvnjmVcSQGjiwuonDickUPzA65cJFgKeklKLV0hXth6lI0Hm9jT0M6+Y+0cbOw8uX/a6KGMLs7nspJi7r2ygutnjmZq2VBd8BQ5AwW9JJXucIR/f20f33x5N8c7QgzNz2HyqCKumDCcj1xRzsKJw5lfUUpxQW7QpYqkDAW9JIU1e47x+Z+9zd6GdgBmXjKMb32skgUVAz93iEi6U9BLoHYcaeVfnt/Jr7YcwQw+csV4PjBzNB+cO1YBL5IgCnoJhLvz9Rd28a8v7mJIbjb3Xz2Zz9wwjZJCdcmIJJqCXgZFJOp87/V9PL2xlrqWLo6199AdjjK+dAjff2ARU8uGBl2iSNpS0MuAqmvt4j+rDvHvr+2joa2b+RNKuWrqSEYW5TFrbDG3zRunSbVEBpiCXhLO3fnNrgaeqjrIM5tiz6AZNTSfR+9dwJI5l2gIpMggU9BLwoQjUb78zDZ+uuEQrV1hhubn8PHrprB0zljmjC/RnDAiAVHQS0KEIlH+7KmNPL2xlptnj+GGWaO5ff54CnI1vYBI0BT0ctFCkSjX//NLHGzs5JOLp/KXt8xQ94xIElHQywVxd9q6w/zXW7U89vJuDh3v5K7KcoW8SBJS0Mt5Wbevkb9/ZhvVdW20dYcBuKKilD+9YRp3VU4IuDoRORMFvfTLsbZufvFWLY+sriY327hjYTnjSguYOLKIm2aN0V2sIklMQS99amjr5r5vr2X7kVbKhw/h8ft1g5NIKlHQy7vsbWjnmy/vZt+xdg4d7+Rwcxc5Wcaj9y7g1rljgy5PRM6Tgl5Ocnf++bmdrHhlDzlZxuyxxSycGHuw9QfnjmP2uOKgSxSRC6Cgz3ANbd08/vo+ttS2sO9YO3vq27l+5mj++oOzmKLuGZG0oKDPYP9ZdZCH/2sLnaEIMy8ZxpRRQ/mD903i9xZVaP4ZkTSioM9AR1u6+PoLO3ly3UEqRhTyjbuvYN6E0qDLEpEBoqDPIB09YZ7eWMtXVm2nuTPEtdPL+Nffnc/worygSxORAaSgzwDuzrNbjvKVVds40NjB3PElfO2ueUwbMyzo0kRkECjo01hXKMKTbxzg0Zd3c7SlmzHF+Tx23wJuuUxTBYtkEgV9mtp+pIX7vv0GDW3dzCsv4c9vnsHt88eTl6OLrCKZRkGfhmqaOrnz0d8Sceex+xZw46wxGkUjksEU9GmmrTvM157bSWt3mGf+9BouG1cSdEkiEjAFfRo50tzFx767lp1H27hzYblCXkQABX3aeOtgEx/7zlpausJ8+2OV3DBrdNAliUiS6FfHrZktMbMdZlZtZg+dYX+Fma02szfNbJOZLU18qXI2Vfsa+aPHqxian8PP/vh93Dh7jEbViMhJfZ7Rm1k28AhwE3AIWGdmK919a69mfw085e6PmtlsYBUwaQDqlV6OtnTx0E83sXpHPeXDh/C9P3wPl47W2HgReaf+dN0sAqrdfQ+AmT0J3A70DnoHTkxtWALUJrJIebfWrhB3r1jD3oZ2PvWBqXz8uqkUF+QGXZaIJKH+BP144GCv9UPAlae1+SLwnJn9CVAE3HimNzKz5cBygIqKivOtVeL2NbTziR+s52BjB9/9g0qunzkm6JJEJIkl6mLsPcD33P2fzey9wBNmNsfdo70bufsKYAVAZWWlJ+izM0ZLV4jl369izZ5GAL7y4bkKeRHpU3+Cvgbo/dTn8vi23h4AlgC4+2/NrAAYBdQlokiJ+coz23hjbyN/ccsMls4dy+RRRUGXJCIpoD+jbtYB08xsspnlAXcDK09rcwC4AcDMZgEFQH0iC810q94+zJPrDvLgtVP41AcuVciLSL/1GfTuHgY+DTwLbCM2umaLmX3JzG6LN/sc8KCZbQR+DPyBu6trJgHcnSd+u48//uEG5owv5n/eOD3okkQkxfSrj97dVxEbMtl728O9lrcCVye2NAlHoix/Yj2/3l7H+6eN4v/cOY+C3OygyxKRFKM7Y5PUrzYf5t9WV7O5poXP3jiNz9wwTTdBicgF0ZSGSeg3O+v5xA820NoV5uFlsxXyInJRdEafZNq7w/zVL96mbFg+z372WnXViMhFU9Anma+s2sbBxk4ev3+RQl5EEkJBnyTcnUdWV/PDtQd48P2TuW56WdAliUiaUNAnge5whId/sYX/qDrIgopSPnfzjKBLEpE0oqAPWFt3mLtX/JbNNS3csbCcf/jIXD32T0QSSkEfsAe+t47NNS38zbLZ3H/1JI2uEZGEU9AHaOXGWtbubeTOheU8cM3koMsRkTSloA9ATzjK3/33Vp5Ys59JIwt56NaZQZckImlMQR+Af/jldp5Ys597FlXwN8tmUZinfw0iMnCUMIOoKxThy89s5QdrDnDbvHH874/MDbokEckACvpB0twR4o7HXmdXXRv3LKrgyx+aE3RJIpIhFPSD5LHf7GZXXRv/+NHLues9E/r+BRGRBNGA7UHwenUDj760m/dNHamQF5FBp6AfYIeOd/BH369ifOkQvv6784MuR0QykIJ+gP3lTzbRFYrw+P3vYXRxQdDliEgGUtAPoPrWbl7ffYz7r57MpaOHBV2OiGQoBf0A+uqvtgPwwcvHBlyJiGQyBf0AcXde2lHHDTNHc0XF8KDLEZEMpuGVAyAadb72/E4a2npYMueSoMsRkQynM/oB8K1X9vBvq6uZN6GUD10xPuhyRCTDKegT7MVtR/nHZ3cwZ3wxP/nEe8nV3PIiEjClUAKt3lHHn/z4TaaWFfGDB65UyItIUlASJcie+jb+9EdvUpiXw6P3LaS0MC/okkREAF2MTZhHVu8m6s7PPvk+KkYWBl2OiMhJOqNPgK5QhOe2HOH6WWMU8iKSdBT0CfD67gZau8N8aP64oEsREXkXBX0CvLCtjiG52Vx96aigSxEReRcF/UUKRaKsevswV00ZQUFudtDliIi8i4L+Ir2w9ShNHSF+Z566bUQkOSnoL8KR5i6+8PO3KRmSy9K5mrhMRJKThldehH95fifHO0L86MEr1W0jIklLZ/QXqL61m6c31XLbvHG8b6ouwopI8upX0JvZEjPbYWbVZvbQWdrcZWZbzWyLmf0osWUml/buMJ958k16wlE+uXhq0OWIiJxTn103ZpYNPALcBBwC1pnZSnff2qvNNODzwNXuftzMRg9Uwcngiyu38PruYzz4/snMGlscdDkiIufUnzP6RUC1u+9x9x7gSeD209o8CDzi7scB3L0usWUmj2jUeXF7HddOL+MLS2cFXY6ISJ/6E/TjgYO91g/Ft/U2HZhuZq+Z2RozW3KmNzKz5WZWZWZV9fX1F1ZxgLpCEZY/UUVjew+3zxuHmQVdkohInxJ1MTYHmAYsBu4BvmVmpac3cvcV7l7p7pVlZWUJ+ujB851X9/LCtjo+ft0UPrJADxQRkdTQn6CvASb0Wi+Pb+vtELDS3UPuvhfYSSz400YoEuWxl3ezoKKUh5bM1Nm8iKSM/gT9OmCamU02szzgbmDlaW1+QexsHjMbRawrZ08C6wzc+v3Hae0Ks/zaKQp5EUkpfQa9u4eBTwPPAtuAp9x9i5l9ycxuizd7FjhmZluB1cBfuPuxgSo6CC9sPUputnHNtNTrchKRzNavO2PdfRWw6rRtD/daduDP4j9pZ/uRFr796l7eP20UQ/N1M7GIpBbdGdsP//7qPobkZvOVD88NuhQRkfOmoO+Du/Pi9qN8YGYZE0bo6VEiknoU9H340RsHaGjrYfH0tL7ZV0TSmIL+HLrDEb7839uYV17ChzVuXkRSlIL+HFZvr6czFOGzN00nN1uHSkRSk9LrLKJR5//+ehfD8nNYNGlE0OWIiFwwBf1ZrNxYy5baFj6/dBZFGlIpIilMQX8G7s73f7uPSSMLufs9E/psLyKSzBT0Z7C7vo0NB5q498qJZGVpugMRSW0K+jN4fmtsOv1l8/TAbxFJfQr6M3hh21HmjC9mbMmQoEsREbloCvrTHGnuYv3+49wy+5KgSxERSQgF/Wme23oEgFvnKuhFJD0o6E/zq81HmFJWxKWjhwVdiohIQijoeznS3MVv9xzjdy4fF3QpIiIJo6Dv5emNtbjDsss12kZE0oeCvpdXqxuYPKqIaWPUbSMi6UNBH7f/WDsv76znptljgi5FRCShFPRx33plD2bwe4sqgi5FRCShFPRAJOo8v/UoN8wczaRRRUGXIyKSUAp6YGttC0dburn5Mo2dF5H0o6AH1uw5BsB108sCrkREJPEU9MDavY1MGlnImOKCoEsREUk4BT2w6VATCyqGB12GiMiAyPigf2VXPXWt3cy4RGPnRSQ9ZXzQf/PlPZQW5nJnpZ4kJSLpKaODvrkjxBt7G7ljQTkjivKCLkdEZEBkdNCv3FhDTyTKUs1tIyJpLKOD/qcbapgyqoh55aVBlyIiMmAyNuibOnrYdKiJZfPGka0HgItIGsvYoH+1uoGow3XTRwVdiojIgMrYoP/NznqGFeSo20ZE0l5GBn1XKMKvt9dxzaWjyMnOyEMgIhkkI1Nu/f7jNLT1cMfC8qBLEREZcBkZ9Bv2H8cM5o4vCboUEZEB16+gN7MlZrbDzKrN7KFztPuombmZVSauxMR7aWc9s8cWM1qTmIlIBugz6M0sG3gEuBWYDdxjZrPP0G4Y8BlgbaKLTKRfvn2Y9fuP8zvzxgVdiojIoOjPGf0ioNrd97h7D/AkcPsZ2v0d8FWgK4H1Jdw3fl3NqKH5/I+rJgZdiojIoOhP0I8HDvZaPxTfdpKZLQAmuPsz53ojM1tuZlVmVlVfX3/exV6s1q4Q24+0cN9VFRTl5wz654uIBOGiL8aaWRbwNeBzfbV19xXuXunulWVlg/80pw0HmnCHhRM197yIZI7+BH0N0HsO3/L4thOGAXOAl8xsH3AVsDLZLsi6O99/fR/FBTl6yIiIZJT+BP06YJqZTTazPOBuYOWJne7e7O6j3H2Su08C1gC3uXvVgFR8gXYebePF7XU8+P4p6rYRkYzSZ9C7exj4NPAssA14yt23mNmXzOy2gS4wUTYcOA6gKYlFJOP069TW3VcBq07b9vBZ2i6++LIS77XqBkYPy2fKqKKgSxERGVQZcWdsdzjC6u11XH3pKMw0JbGIZJaMCPpHX9pNe0+EJXMuCboUEZFBl/ZB7+48vbGW+RNKueUyBb2IZJ60D/qth1vYXd+umSpFJGOlfdCvfKuWnCxj6VyNthGRzJTWQd/cGeLHbxxg8YwyRhTlBV2OiEgg0jron95YS0tXmE8unhp0KSIigUnroF/5Vi3jSgpYOHFE0KWIiAQmbYO+vrWbqv2NuggrIhkvbYP+V5sPE3VYpgeMiEiGS9ugf2VXA2OK85k+ZljQpYiIBCotgz4SdV7Z1cANs8YEXYqISODSMug3HWqiMxThysm6CCsikpZBv+FAEwDvnTIy4EpERIKXlkH/5oHjjC0pYHRxQdCliIgELi2DvmrfcT0XVkQkLu2C/nh7D0dauri8vCToUkREkkLaBf3LO+sBmKZhlSIiQBoG/Z6GdgCunjoq4EpERJJD2gX94aZORg/LJy8n7f40EZELklZp6O5sO9LChBGFQZciIpI00iroa5o62VzTws2zdUesiMgJaRX0m2taALhSN0qJiJyUVkG/7XALZjBDI25ERE5Km6B3d57dcoSKEYUMycsOuhwRkaSRNkG/82gb24+0cqceNCIi8g5pE/Tbj8T652+57JKAKxERSS5pE/Rr9zaSl5OloZUiIqdJm6B/aXsdN80eQ0Gu+udFRHpLi6Bv7ghR29zFnHGayExE5HRpEfQ7jrYCMPMSDasUETldegR9/ELsDAW9iMi7pEXQv1Z9jJIhuYwt0ROlREROl/JBH406r1U3sHhGGWYWdDkiIkmnX0FvZkvMbIeZVZvZQ2fY/2dmttXMNpnZi2Y2MfGlntn+xg5au8N6ELiIyFn0GfRmlg08AtwKzAbuMbPZpzV7E6h098uBnwD/mOhCz2bjwSYA5k0oHayPFBFJKf05o18EVLv7HnfvAZ4Ebu/dwN1Xu3tHfHUNMGjzEKzZc4zcbGNKWdFgfaSISErpT9CPBw72Wj8U33Y2DwC/PNMOM1tuZlVmVlVfX9//Ks8iHIny4vY6KieOID9HN0qJiJxJQi/Gmtl9QCXwT2fa7+4r3L3S3SvLysou+vNe2dVAfWs3t80fd9HvJSKSrnL60aYGmNBrvTy+7R3M7Ebgr4Dr3L07MeWd28ZDsf75D14+djA+TkQkJfXnjH4dMM3MJptZHnA3sLJ3AzO7AvgmcJu71yW+zDN7+1Azl44eSnFB7mB9pIhIyukz6N09DHwaeBbYBjzl7lvM7Etmdlu82T8BQ4H/NLO3zGzlWd4uobYdbuGyccWD8VEiIimrP103uPsqYNVp2x7utXxjguvq076Gdmqbu5hXrmGVIiLnkrJ3xj69sRaAxTMu/qKuiEg6S9mg31TTzORRRUwpGxp0KSIiSS0lg76zJ8JLO+p471RNeyAi0peUDPq3DjYRijg3zRoTdCkiIkkvJYO+al8jZrCgYnjQpYiIJL2UDPp1+48zffQwSgo1fl5EpC8pF/R76tt4ZVc9CyZqWKWISH+kXNCv3FiLO3ziuqlBlyIikhJSLuhf3dXA/AmlTBypaYlFRPojpYI+HImyubZZF2FFRM5DSgX94eYuukJRpo/RTVIiIv2VUkFftb8RgDnjSwKuREQkdaRU0L+wrY4RRXnMHqsZK0VE+itlgr6xvYfV2+u45bIxZGVZ0OWIiKSMlAn6b7y4i46eCPdeOTHoUkREUkrKBP2aPcd439SR6p8XETlPKRH0NU2dbD/SSuVEDasUETlfKRH0z24+AsCyeeMCrkREJPWkRNCv3lHH9DFDmT5mWNCliIiknKQP+oONHbxa3cCiySOCLkVEJCUlfdD//M0a3OHj12oSMxGRC5H0Qf/sliMsmjSCCSMKgy5FRCQlJXXQN7b3sONIKws02kZE5IIlddC/sbeRcNRZPKMs6FJERFJWUgf9c1uPkJttuklKROQiJG3Qd4UiPL/1KLfNG8/Q/JygyxERSVlJG/Sr3j5Ma1eYD18xPuhSRERSWtIG/cqNtYwpzue9U0cGXYqISEpLyqDf19DOSzvqWXb5OLI1JbGIyEVJuqDv6Alz33fWAnBX5YSAqxERSX1JF/Q/3VDDoeOdfGHpTGZcorltREQuVlIFfVcowv9bXc3kUUU8+P4pQZcjIpIWkirof7BmP4ebu/jczdMxU9+8iEgiJE3Qr95Rxz/8cjsLJw5n6ZyxQZcjIpI2kiLoj7Z08eDjVUwYUcij9y7Qw79FRBKoX0FvZkvMbIeZVZvZQ2fYn29m/xHfv9bMJvXnfSNR5zuv7uWeb60hHHUeu28ho4sLzu8vEBGRc+pzbgEzywYeAW4CDgHrzGylu2/t1ewB4Li7X2pmdwNfBX73XO8bjjp3PvY6Gw40AfDwstkaZSMiMgD6M4nMIqDa3fcAmNmTwO1A76C/HfhifPknwL+Zmbm7n+1Nd9e10XSgia9+dC4fXVBOTnZS9CKJiKSd/gT9eOBgr/VDwJVna+PuYTNrBkYCDb0bmdlyYHl8tbvtq8s23/3VCyk77YzitGOVwXQsTtGxOEXH4pQZ5/sLgzotpLuvAFYAmFmVu1cO5ucnKx2LU3QsTtGxOEXH4hQzqzrf3+lPf0kN0HsugvL4tjO2MbMcoAQ4dr7FiIhI4vUn6NcB08xsspnlAXcDK09rsxL4/fjyHcCvz9U/LyIig6fPrpt4n/ungWeBbOC77r7FzL4EVLn7SuA7wBNmVg00EvufQV9WXETd6UbH4hQdi1N0LE7RsTjlvI+F6cRbRCS9aUyjiEiaU9CLiKS5QIK+rykV0pmZfdfM6sxsc69tI8zseTPbFX8dHmSNg8HMJpjZajPbamZbzOwz8e2ZeCwKzOwNM9sYPxb/K759cnxKker4FCN5Qdc6WMws28zeNLP/jq9n5LEws31m9raZvXViWOWFfEcGPeh7TalwKzAbuMfMZg92HQH6HrDktG0PAS+6+zTgxfh6ugsDn3P32cBVwKfi/x1k4rHoBq5393nAfGCJmV1FbCqRf3H3S4HjxKYayRSfAbb1Ws/kY/EBd5/f6z6C8/6OBHFGf3JKBXfvAU5MqZAR3P03xEYm9XY78Hh8+XHgQ4NaVADc/bC7b4gvtxL7Uo8nM4+Fu3tbfDU3/uPA9cSmFIEMORYAZlYOfBD4dnzdyNBjcRbn/R0JIujPNKXC+ADqSCZj3P1wfPkIMCbIYgZbfLbTK4C1ZOixiHdVvAXUAc8Du4Emdw/Hm2TS9+TrwF8C0fj6SDL3WDjwnJmtj08hAxfwHRnUKRCkb+7uZpYxY17NbCjwU+Cz7t7S+8limXQs3D0CzDezUuDnwMyASwqEmS0D6tx9vZktDrqeJHCNu9eY2WjgeTPb3ntnf78jQZzR92dKhUxz1MzGAsRf6wKuZ1CYWS6xkP+hu/8svjkjj8UJ7t4ErAbeC5TGpxSBzPmeXA3cZmb7iHXrXg/8K5l5LHD3mvhrHbETgEVcwHckiKDvz5QKmab3FBK/D/xXgLUMini/63eAbe7+tV67MvFYlMXP5DGzIcSe/bCNWODfEW+WEcfC3T/v7uXuPolYNvza3e8lA4+FmRWZ2bATy8DNwGYu4DsSyJ2xZraUWD/ciSkV/n7QiwiImf0YWExs2tWjwN8CvwCeAiqA/cBd7n76Bdu0YmbXAK8Ab3OqL/YLxPrpM+1YXE7solo2sZOvp9z9S2Y2hdhZ7QjgTeA+d+8OrtLBFe+6+XN3X5aJxyL+N/88vpoD/Mjd/97MRnKe3xFNgSAikuZ0Z6yISJpT0IuIpDkFvYhImlPQi4ikOQW9iEiaU9CLiKQ5Bb2ISJr7/4bZyc4I0HLjAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing to file name:  cnn_lstm_layer_altered_2_db.txt\n",
      "(None, None, 1)\n",
      "WARNING:tensorflow:The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "Train on 19937 samples\n",
      "Epoch 1/100\n",
      "19937/19937 [==============================] - 54s 3ms/sample - loss: 0.0205 - mse: 0.0205\n",
      "Epoch 2/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 3/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0036 - mse: 0.0036\n",
      "Epoch 4/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0030 - mse: 0.0030\n",
      "Epoch 5/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0030 - mse: 0.0030\n",
      "Epoch 6/100\n",
      "19937/19937 [==============================] - 50s 3ms/sample - loss: 0.0025 - mse: 0.0025\n",
      "Epoch 7/100\n",
      "19937/19937 [==============================] - 52s 3ms/sample - loss: 0.0026 - mse: 0.0026\n",
      "Epoch 8/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0025 - mse: 0.0025\n",
      "Epoch 9/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0024 - mse: 0.0024\n",
      "Epoch 10/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0023 - mse: 0.0023\n",
      "Epoch 11/100\n",
      "19937/19937 [==============================] - 52s 3ms/sample - loss: 0.0023 - mse: 0.0023\n",
      "Epoch 12/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0021 - mse: 0.0021\n",
      "Epoch 13/100\n",
      "19937/19937 [==============================] - 50s 3ms/sample - loss: 0.0023 - mse: 0.0023\n",
      "Epoch 14/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0023 - mse: 0.0023\n",
      "Epoch 15/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0021 - mse: 0.0021\n",
      "Epoch 16/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0021 - mse: 0.0021\n",
      "Epoch 17/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0022 - mse: 0.0022\n",
      "Epoch 18/100\n",
      "19937/19937 [==============================] - 50s 3ms/sample - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 19/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0021 - mse: 0.0021\n",
      "Epoch 20/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 21/100\n",
      "19937/19937 [==============================] - 50s 3ms/sample - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 22/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0022 - mse: 0.0022\n",
      "Epoch 23/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 24/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 25/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 26/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0019 - mse: 0.0019\n",
      "Epoch 27/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0019 - mse: 0.0019\n",
      "Epoch 28/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0021 - mse: 0.0021\n",
      "Epoch 29/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0021 - mse: 0.0021\n",
      "Epoch 30/100\n",
      "19937/19937 [==============================] - 52s 3ms/sample - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 31/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0019 - mse: 0.0019\n",
      "Epoch 32/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0019 - mse: 0.0019\n",
      "Epoch 33/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 34/100\n",
      "19937/19937 [==============================] - 52s 3ms/sample - loss: 0.0019 - mse: 0.0019\n",
      "Epoch 35/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0019 - mse: 0.0019\n",
      "Epoch 36/100\n",
      "19937/19937 [==============================] - 52s 3ms/sample - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 37/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 38/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0019 - mse: 0.0019\n",
      "Epoch 39/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 40/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0019 - mse: 0.0019\n",
      "Epoch 41/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 42/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 43/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 44/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0019 - mse: 0.0019\n",
      "Epoch 45/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0019 - mse: 0.0019\n",
      "Epoch 46/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0019 - mse: 0.0019\n",
      "Epoch 47/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0019 - mse: 0.0019\n",
      "Epoch 48/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 49/100\n",
      "19937/19937 [==============================] - 50s 3ms/sample - loss: 0.0019 - mse: 0.0019\n",
      "Epoch 50/100\n",
      "19937/19937 [==============================] - 50s 3ms/sample - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 51/100\n",
      "19937/19937 [==============================] - 50s 3ms/sample - loss: 0.0019 - mse: 0.0019\n",
      "Epoch 52/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 53/100\n",
      "19937/19937 [==============================] - 50s 3ms/sample - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 54/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 55/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 56/100\n",
      "19937/19937 [==============================] - 52s 3ms/sample - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 57/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 58/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 59/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 60/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 61/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 62/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 63/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 64/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 65/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 66/100\n",
      "19937/19937 [==============================] - 54s 3ms/sample - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 67/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 68/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 69/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0019 - mse: 0.0019\n",
      "Epoch 70/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 71/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 72/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 73/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 74/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 75/100\n",
      "19937/19937 [==============================] - 50s 3ms/sample - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 76/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 77/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 79/100\n",
      "19937/19937 [==============================] - 50s 3ms/sample - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 80/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 81/100\n",
      "19937/19937 [==============================] - 52s 3ms/sample - loss: 0.0016 - mse: 0.0016\n",
      "Epoch 82/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0016 - mse: 0.0016\n",
      "Epoch 83/100\n",
      "19937/19937 [==============================] - 50s 3ms/sample - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 84/100\n",
      "19937/19937 [==============================] - 52s 3ms/sample - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 85/100\n",
      "19937/19937 [==============================] - 53s 3ms/sample - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 86/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 87/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 88/100\n",
      "19937/19937 [==============================] - 50s 3ms/sample - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 89/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0016 - mse: 0.0016\n",
      "Epoch 90/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0016 - mse: 0.0016\n",
      "Epoch 91/100\n",
      "19937/19937 [==============================] - 50s 3ms/sample - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 92/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0016 - mse: 0.0016\n",
      "Epoch 93/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0016 - mse: 0.0016\n",
      "Epoch 94/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0015 - mse: 0.0015\n",
      "Epoch 95/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0016 - mse: 0.0016\n",
      "Epoch 96/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0016 - mse: 0.0016\n",
      "Epoch 97/100\n",
      "19937/19937 [==============================] - 50s 3ms/sample - loss: 0.0015 - mse: 0.0015\n",
      "Epoch 98/100\n",
      "19937/19937 [==============================] - 50s 3ms/sample - loss: 0.0015 - mse: 0.0015\n",
      "Epoch 99/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0015 - mse: 0.0015\n",
      "Epoch 100/100\n",
      "19937/19937 [==============================] - 51s 3ms/sample - loss: 0.0015 - mse: 0.0015\n",
      "rms_error: 11.88444007184945\n",
      "mean_error: 9.161328888634179\n",
      "generating cdf:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'ratio' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-2a7e9353ec79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m \u001b[0maltered_rssi_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-2a7e9353ec79>\u001b[0m in \u001b[0;36maltered_rssi_analysis\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mtest_pred_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_pred_y\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mranges\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0merror_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pred_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mfileName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'lstm_layer_altered_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0;34m'_db.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"writing to file name: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileName\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'ratio' referenced before assignment"
     ]
    }
   ],
   "source": [
    "def altered_rssi_analysis():\n",
    "    from sklearn import neighbors\n",
    "    path_train = \"trainingData.csv\"\n",
    "    path_validation = \"validationData.csv\"\n",
    "    train_df = pd.read_csv(path_train,header = 0)\n",
    "    train_AP_strengths =train_df.loc[:,'WAP001':'WAP520']\n",
    "    building_ids_str = train_df[\"BUILDINGID\"].map(str) #convert all the building ids to strings\n",
    "    building_floors_str = train_df[\"FLOOR\"].map(str) #convert all the building floors to strings\n",
    "    floor_enc = LabelEncoder()\n",
    "    floor_enc.fit(building_floors_str)\n",
    "    floor_id = floor_enc.transform(building_floors_str)\n",
    "    floor_id = floor_id.reshape(-1,1)\n",
    "    building_enc = LabelEncoder()\n",
    "    building_enc.fit(building_ids_str)\n",
    "    building_id = building_enc.transform(building_ids_str)\n",
    "    train_building_id = building_id.reshape(-1,1)\n",
    "    train_AP_features = np.array(train_AP_strengths.replace([100],[-150]))\n",
    "    train_id = np.argsort(train_AP_features)[:,504:520]\n",
    "    train_rssi = np.sort(train_AP_features)[:,504:520]\n",
    "    print(train_rssi[10])\n",
    "    print(train_id[10])\n",
    "    print(train_AP_features[train_id[10]])\n",
    "    train_df_LL = train_df.loc[:,'LONGITUDE':'LATITUDE']\n",
    "    train_labels = np.asarray(train_df_LL)\n",
    "    train_y,ranges,bias =  normalization(train_labels)\n",
    "    print(bias,ranges)\n",
    "    test_df = pd.read_csv(path_validation,header = 0)\n",
    "    print(test_df.head(2))\n",
    "    test_AP_strengths =test_df.loc[:,'WAP001':'WAP520']\n",
    "    #test_AP_features = np.array(test_AP_strengths.replace([100], [-100]))\n",
    "    test_building_ids_str = test_df[\"BUILDINGID\"].map(str) #convert all the building ids to strings\n",
    "    test_building_floors_str = test_df[\"FLOOR\"].map(str) #convert all the building floors to strings\n",
    "    #print(id_label)\n",
    "    test_floor_enc = LabelEncoder()\n",
    "    test_floor_enc.fit(building_floors_str)\n",
    "    test_floor_id = test_floor_enc.transform(test_building_floors_str)\n",
    "    test_floor_id = test_floor_id.reshape(-1,1)\n",
    "    print(\"test floor id\",(test_floor_id.shape))\n",
    "    test_building_enc = LabelEncoder()\n",
    "    test_building_enc.fit(test_building_ids_str)\n",
    "    test_building_id = test_building_enc.transform(test_building_ids_str)\n",
    "    test_building_id = test_building_id.reshape(-1,1)\n",
    "    print(\"test building id:\",(test_building_id.shape))\n",
    "    test_AP_features = np.array(test_AP_strengths.replace([100],[-150]))\n",
    "    test_id = np.argsort(test_AP_features)[:,504:520]\n",
    "    test_rssi = np.sort(test_AP_features)[:,504:520]\n",
    "    test_rssi_floor = np.hstack((test_rssi,test_floor_id))\n",
    "    print(test_rssi_floor[0], test_rssi_floor.shape)\n",
    "    test_df_LL = test_df.loc[:,'LONGITUDE':'LATITUDE']\n",
    "    test_y = np.asarray(test_df_LL)\n",
    "    for i in range(2,5):\n",
    "\n",
    "        train_rssi =  train_rssi + np.random.normal(0, 2*i, None)\n",
    "        input_data = [train_id, train_rssi, train_building_id]\n",
    "\n",
    "        model = cnn_lstm(input_data)\n",
    "        #model.compile(optimizer=tf.optimizers.Adam(lr=0.001), loss='mse', metrics=['mse'])\n",
    "        model.fit(input_data,train_y,nb_epoch=100,batch_size=128,verbose = 1)\n",
    "        test_pred_y = model.predict([test_id, test_rssi, test_building_id])\n",
    "        test_pred_y = test_pred_y * ranges + bias \n",
    "        error_analysis(test_y, test_pred_y)\n",
    "        fileName = 'cnn_lstm_layer_altered_' + str(2*i)+ '_db.txt'\n",
    "        print(\"writing to file name: \", fileName)\n",
    "        file = open(fileName,'wb')\n",
    "        pickle.dump(test_pred_y,file)\n",
    "        file.close()\n",
    "\n",
    "        \n",
    "        model = lstm(input_data)\n",
    "        #model.compile(optimizer=tf.optimizers.Adam(lr=0.001), loss='mse', metrics=['mse'])\n",
    "        model.fit(input_data,train_y,nb_epoch=100,batch_size=128,verbose = 1)\n",
    "        test_pred_y = model.predict([test_id, test_rssi, test_building_id])\n",
    "        test_pred_y = test_pred_y * ranges + bias \n",
    "        error_analysis(test_y, test_pred_y)\n",
    "        fileName = 'lstm_layer_altered_' + str(2*i)+ '_db.txt'\n",
    "        print(\"writing to file name: \", fileName)\n",
    "        file = open(fileName,'wb')\n",
    "        pickle.dump(test_pred_y,file)\n",
    "        file.close()\n",
    "        continue\n",
    "        \n",
    "        #cnn_LSTM\n",
    "        model = cnn_lstm(input_data)\n",
    "        #model.compile(optimizer=tf.optimizers.Adam(lr=0.001), loss='mse', metrics=['mse'])\n",
    "        model.fit(input_data,train_y,nb_epoch=100,batch_size=128,verbose = 1)\n",
    "        test_pred_y = model.predict([test_id, test_rssi, test_building_id])\n",
    "        test_pred_y = test_pred_y * ranges + bias \n",
    "        error_analysis(test_y, test_pred_y)\n",
    "        fileName = 'cnn_lstm_layer_altered_' + str(2*i)+ '_db.txt'\n",
    "        print(\"writing to file name: \", fileName)\n",
    "        file = open(fileName,'wb')\n",
    "        pickle.dump(test_pred_y,file)\n",
    "        file.close()\n",
    "\n",
    "        continue\n",
    "        # CNN\n",
    "        model = cnn(input_data)\n",
    "        #model.compile(optimizer=tf.optimizers.Adam(lr=0.001), loss='mse', metrics=['mse'])\n",
    "        model.fit(input_data,train_y,nb_epoch=100,batch_size=128,verbose = 1)\n",
    "        test_pred_y = model.predict([test_id, test_rssi, test_building_id])\n",
    "        test_pred_y = test_pred_y * ranges + bias \n",
    "        error_analysis(test_y, test_pred_y)\n",
    "        fileName = 'cnn_layer_altered_' + str(i*2)+ '_db.txt'\n",
    "        print(\"writing to file name: \", fileName)\n",
    "        file = open(fileName,'wb')\n",
    "        pickle.dump(test_pred_y,file)\n",
    "        file.close()\n",
    "        ratio = i * 2\n",
    "\n",
    "        # MLP\n",
    "\n",
    "        model = mlp(input_data)\n",
    "        model.fit(input_data,train_y,nb_epoch=100,batch_size=128,verbose = 1)\n",
    "        test_pred_y = model.predict([test_id, test_rssi, test_building_id])\n",
    "        test_pred_y = test_pred_y * ranges + bias \n",
    "        error_analysis(test_y, test_pred_y)\n",
    "        fileName = 'mlp_layer_altered_' + str(ratio)+ '_db.txt'\n",
    "        print(\"writing to file name: \", fileName)\n",
    "        file = open(fileName,'wb')\n",
    "        pickle.dump(test_pred_y,file)\n",
    "        file.close()\n",
    "        #LSTM\n",
    "\n",
    "\n",
    "altered_rssi_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(path_validation,header = 0)\n",
    "print(test_df.head(2))\n",
    "test_AP_strengths =test_df.loc[:,'WAP001':'WAP520']\n",
    "#test_AP_features = np.array(test_AP_strengths.replace([100], [-100]))\n",
    "test_building_ids_str = test_df[\"BUILDINGID\"].map(str) #convert all the building ids to strings\n",
    "test_building_floors_str = test_df[\"FLOOR\"].map(str) #convert all the building floors to strings\n",
    "#print(id_label)\n",
    "test_floor_enc = LabelEncoder()\n",
    "test_floor_enc.fit(building_floors_str)\n",
    "test_floor_id = test_floor_enc.transform(test_building_floors_str)\n",
    "test_floor_id = test_floor_id.reshape(-1,1)\n",
    "print(\"test floor id\",(test_floor_id.shape))\n",
    "test_building_enc = LabelEncoder()\n",
    "test_building_enc.fit(test_building_ids_str)\n",
    "test_building_id = test_building_enc.transform(test_building_ids_str)\n",
    "test_building_id = test_building_id.reshape(-1,1)\n",
    "print(\"test building id:\",(test_building_id.shape))\n",
    "test_AP_features = np.array(test_AP_strengths.replace([100],[-100]))\n",
    "test_id = np.argsort(test_AP_features)[:,500:520]\n",
    "test_rssi = np.sort(test_AP_features)[:,500:520]\n",
    "\n",
    "test_rssi_floor = np.hstack((test_rssi,test_floor_id))\n",
    "print(test_rssi_floor[0], test_rssi_floor.shape)\n",
    "\n",
    "test_df_LL = test_df.loc[:,'LONGITUDE':'LATITUDE']\n",
    "test_y = np.asarray(test_df_LL)\n",
    "test_pred_y = model.predict([test_id, test_rssi, test_building_id])\n",
    "test_pred_y = test_pred_y * ranges + bias \n",
    "error_analysis(test_y, test_pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
